{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "* Common Import Issues (Infering Types, Infering Missing Values, Records with Errors)\n",
    "* Types of Ingestion (CSV, Excel, APIs/JSONs, Relational Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Import Issues\n",
    "* Data types: \n",
    "    * Pandas infer types, but it might infer incorrectly: read_csv(dtype = {\"col\":type})\n",
    "    * Pandas infer missing values, but it might infer incorrectly: read_csv(na_values={\"col\" : 0}), where 0 should be interpreted as missing value.\n",
    "    * Lines with errors: a record could have more values than columns, so this will cause a parsing error: read_csv(error_bad_lines = False, warn_bad_lines = True), which will show messages when records are skipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting from a local CSV\n",
    "* Flat Files\n",
    "* Source: https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2016-zip-code-data-soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ZIPCODE AGI_STUB   MARS1   MARS2   NUMDEP\n",
      "0     NaN        0  825680  748830  1417040\n",
      "1   35004        0    2150    2140     3430\n",
      "2   35005        0    1340     890     2170\n",
      "3   35006        0     430     600      820\n",
      "4   35007        0    4770    5140     8840\n",
      "ZIPCODE       object\n",
      "AGI_STUB    category\n",
      "MARS1          int64\n",
      "MARS2          int64\n",
      "NUMDEP         int64\n",
      "dtype: object\n",
      "(1000, 5)\n",
      "    ZIPCODE AGI_STUB    MARS1    MARS2   NUMDEP\n",
      "0       NaN        0   825680   748830  1417040\n",
      "594     NaN        0   173420   125440   204720\n",
      "750     NaN        0  1315560  1068920  2026700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "file_path = \"/workspace/sources/datacamp/general_datasets/us_tax_data_2016.csv\"\n",
    "\n",
    "# Create list of columns to use\n",
    "cols = [\"ZIPCODE\", \"AGI_STUB\", \"MARS1\", \"MARS2\", \"NUMDEP\"]\n",
    "\n",
    "# Create dict specifying data types for agi_stub and zipcode\n",
    "data_types = {'AGI_STUB':'category',\n",
    "\t\t\t  'ZIPCODE':str}\n",
    "\n",
    "# Create dict specifying that 0s in zipcode are NA values\n",
    "null_values = {'ZIPCODE':0}\n",
    "\n",
    "try:\n",
    "  # Set warn_bad_lines to issue warnings about bad records as well as other parameters\n",
    "  data = pd.read_csv(file_path, \n",
    "                     nrows=1000,\n",
    "                     skiprows=0,\n",
    "                     usecols=cols,\n",
    "                     dtype = data_types,\n",
    "                     na_values=null_values,\n",
    "                     on_bad_lines = 'warn')\n",
    "  \n",
    "  # View first 5 records\n",
    "  print(data.head())\n",
    "  \n",
    "except pd.errors.ParserError:\n",
    "    print(\"Your data contained rows that could not be parsed.\")\n",
    "\n",
    "# Print data types of resulting frame\n",
    "print(data.dtypes.head())\n",
    "print(data.shape)\n",
    "\n",
    "# View rows with NA ZIP codes\n",
    "print(data[data[\"ZIPCODE\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting from a local Excel\n",
    "* Unlike flat files, Spreadsheets can have formatting and formulas and/or multiple spreadsheets can coexist in a workbook.\n",
    "    * Single file\n",
    "    * Multiple files\n",
    "* Source: https://github.com/freeCodeCamp/2021-new-coder-survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ONE SPREADSHEET WITHIN EXCEL\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "file_path = \"fcc_survey\"\n",
    "\n",
    "# Create string of lettered columns to load\n",
    "col_string = \"AD, AW:BA\"\n",
    "\n",
    "# Try reading the Excel file with the 'openpyxl' engine\n",
    "try:\n",
    "    survey_responses = pd.read_excel(file_path, \n",
    "                       engine='openpyxl',\n",
    "                       skiprows = 1, \n",
    "                       usecols = col_string)\n",
    "    print(\"File read successfully using openpyxl engine.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    # If 'openpyxl' fails, try with 'xlrd'\n",
    "    try:\n",
    "        survey_responses = pd.read_excel(file_path, \n",
    "                           engine='xlrd',\n",
    "                           skiprows = 1, \n",
    "                           usecols = col_string)\n",
    "        print(\"File read successfully using xlrd engine.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        print(\"Unable to read the Excel file.\")\n",
    "\n",
    "# View the names of the columns selected\n",
    "print(survey_responses.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# MULTIPLE SPREADSHEETS WITHIN EXCEL\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "file_path = \"fcc_survey.xlsx\"\n",
    "\n",
    "# Examples to load sheets\n",
    "    # 1) Load ALL sheets in the Excel file\n",
    "    all_survey_data = pd.read_excel(\"file_path.xlsx\",\n",
    "                                    sheet_name = None)\n",
    "\n",
    "    # 2) Load all sheets in the Excel file with index and name\n",
    "    all_survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                                    sheet_name = [0, '2017'])\n",
    "\n",
    "    # 3) Load both the 2016 and 2017 sheets by name\n",
    "    all_survey_data = pd.read_excel(\"fcc_survey.xlsx\",\n",
    "                                    sheet_name = ['2016', '2017'])\n",
    "    # View the data type of all_survey_data\n",
    "    print(type(all_survey_data)) # type will be a dictionary where keys are the sheetnames and values are the data\n",
    "    print(all_survey_data.keys())\n",
    "\n",
    "    # 4) Create an empty dataframe to hold all loaded sheets and concatenate\n",
    "    all_responses = pd.DataFrame()\n",
    "\n",
    "    # Set up for loop to iterate through values in responses\n",
    "    for df in responses.values():\n",
    "    # Print the number of rows being added\n",
    "    print(\"Adding {} rows\".format(df.shape[0]))\n",
    "    # Concatenate all_responses and df, assign result\n",
    "    all_responses = pd.concat([all_responses, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting from a JSON or an API\n",
    "* JSONs are:\n",
    "    * Non-tabular (unstrcutured) data: it stores information in dictionaries.\n",
    "    * Schema-less: there are no predefined rules or constraints imposed on the structure or content of the JSON data. In other words, there is no formal schema definition that specifies what keys are allowed, what data types are expected, or what the structure of the JSON object should be.\n",
    "    * Because of these properties, a JSON might not be \"dataframe-ready\", as the dictionary values might be nested objects or have varying \"schemas\".\n",
    "        * Variying schemas, means: first element is a dictionary with 2 columns names, second element is a dict with 3 columns names, etc.\n",
    "* JSON: can be record or column oriented, so specifing orientation is important.\n",
    "    * read_json()\n",
    "        * orient='columns' (tell JSON how the dictionary values are stored, in this case, column-wise, i.e, keys are column names and values are column values)\n",
    "        * easier to use when there's some structure in the dictionary, like all elements follow the same pattern (same number of columns or same types of nested objects)\n",
    "    * import json -> open() as file -> json.load()\n",
    "        * better to use when the JSON has varying schema\n",
    "    * Single JSON\n",
    "    * Nested JSONs\n",
    "        * A json contain objects with attribute-value pairs, like a dictionary. A nested json is when a value is itself an object. The idea is to flatten the nested jsons. For that, we use: \n",
    "        * pandas.io.json submodule to read/write jsons.\n",
    "            * It's json_normalize() function takes a dictionary and returns a flattened dataframe\n",
    "        * Naming meta columns can get tedious for datasets with many attributes, and code is susceptible to breaking if column names or nesting levels change. In such cases, you may have to write a custom function and employ techniques like recursion to handle the data.\n",
    "\n",
    "* API: APIs are the most common source of JSON data. \n",
    "    * APIs limit the amount of data you can get in a given timeframe, but you can customize it. (in Yelp, is the offset())\n",
    "    * It provides an endpoint to send requests to. \n",
    "    * Its documentation describes what a request should look like (such as parameters).\n",
    "    * Requests library it's an option. It allows users to send/receive data from an URL\n",
    "        * requests.get(url_string, params = , headers = , ...)\n",
    "        * return.json(): returns just the data in a dict type\n",
    "            * We cannot use read_json, because it expects strings and not dictionaries\n",
    "            * We need to use pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a JSON\n",
    "# Applying Logging with the try-except block (check the data pipelines jupyter notebook)  \n",
    "try:\n",
    "    # Load the JSON without keyword arguments\n",
    "    df = pd.read_json(\"dhs_report_reformatted.json\")\n",
    "    \n",
    "    # Plot total population in shelters over time\n",
    "    df[\"date_of_census\"] = pd.to_datetime(df[\"date_of_census\"])\n",
    "    df.plot(x=\"date_of_census\", \n",
    "            y=\"total_individuals_in_shelter\")\n",
    "    plt.show()\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"pandas could not parse the JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                object\n",
      "alias             object\n",
      "name              object\n",
      "image_url         object\n",
      "is_closed           bool\n",
      "url               object\n",
      "review_count       int64\n",
      "categories        object\n",
      "rating           float64\n",
      "coordinates       object\n",
      "transactions      object\n",
      "price             object\n",
      "location          object\n",
      "phone             object\n",
      "display_phone     object\n",
      "distance         float64\n",
      "attributes        object\n",
      "dtype: object\n",
      "                       id               alias       name  \\\n",
      "0  ED7A7vDdg8yLNKJTSVHHmg    arabica-brooklyn  % Arabica   \n",
      "1  -2UtjTxrt1Xzd-HPsLJ7mA   butler-brooklyn-2     Butler   \n",
      "2  d2y35lqplnZvK0cbMWz7xQ   kijitora-brooklyn   Kijitora   \n",
      "3  bJDU8KNLQMrZG0Ngs4AY0w  le-phin-new-york-2    Le Phin   \n",
      "4  DE0ROwygh-86i4s-WLp8wQ   maman-new-york-22      maman   \n",
      "\n",
      "                                           image_url  is_closed  \\\n",
      "0  https://s3-media2.fl.yelpcdn.com/bphoto/RZ7MHl...      False   \n",
      "1  https://s3-media3.fl.yelpcdn.com/bphoto/bdMNkv...      False   \n",
      "2  https://s3-media3.fl.yelpcdn.com/bphoto/Wj2NnW...      False   \n",
      "3  https://s3-media2.fl.yelpcdn.com/bphoto/I1Yzp3...      False   \n",
      "4  https://s3-media4.fl.yelpcdn.com/bphoto/wfDzNa...      False   \n",
      "\n",
      "                                                 url  review_count  \\\n",
      "0  https://www.yelp.com/biz/arabica-brooklyn?adju...           272   \n",
      "1  https://www.yelp.com/biz/butler-brooklyn-2?adj...           213   \n",
      "2  https://www.yelp.com/biz/kijitora-brooklyn?adj...            38   \n",
      "3  https://www.yelp.com/biz/le-phin-new-york-2?ad...           151   \n",
      "4  https://www.yelp.com/biz/maman-new-york-22?adj...           815   \n",
      "\n",
      "                                          categories  rating  \\\n",
      "0     [{'alias': 'coffee', 'title': 'Coffee & Tea'}]     4.4   \n",
      "1  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...     4.2   \n",
      "2     [{'alias': 'coffee', 'title': 'Coffee & Tea'}]     4.8   \n",
      "3     [{'alias': 'coffee', 'title': 'Coffee & Tea'}]     4.7   \n",
      "4  [{'alias': 'cafes', 'title': 'Cafes'}, {'alias...     3.9   \n",
      "\n",
      "                                         coordinates        transactions  \\\n",
      "0  {'latitude': 40.702601240302045, 'longitude': ...                  []   \n",
      "1  {'latitude': 40.7032670673495, 'longitude': -7...  [delivery, pickup]   \n",
      "2   {'latitude': 40.716485, 'longitude': -73.957276}                  []   \n",
      "3  {'latitude': 40.7286034766475, 'longitude': -7...                  []   \n",
      "4  {'latitude': 40.72033091951731, 'longitude': -...  [delivery, pickup]   \n",
      "\n",
      "  price                                           location         phone  \\\n",
      "0    $$  {'address1': '20 Old Fulton St', 'address2': '...  +17188652551   \n",
      "1    $$  {'address1': '40 Water St', 'address2': '', 'a...                 \n",
      "2   NaN  {'address1': '578 Driggs Ave', 'address2': '',...  +13478767575   \n",
      "3    $$  {'address1': '259 E 10th St', 'address2': None...                 \n",
      "4    $$  {'address1': '239 Centre St', 'address2': None...  +12122260700   \n",
      "\n",
      "    display_phone     distance  \\\n",
      "0  (718) 865-2551   316.425063   \n",
      "1                   299.481415   \n",
      "2  (347) 876-7575  3353.582988   \n",
      "3                  2733.480563   \n",
      "4  (212) 226-0700  1691.163017   \n",
      "\n",
      "                                          attributes  \n",
      "0  {'business_temp_closed': None, 'menu_url': Non...  \n",
      "1  {'business_temp_closed': None, 'menu_url': 'ht...  \n",
      "2  {'business_temp_closed': None, 'menu_url': Non...  \n",
      "3  {'business_temp_closed': None, 'menu_url': Non...  \n",
      "4  {'business_temp_closed': None, 'menu_url': 'ht...  \n",
      "This is the shape of the dataframe returned by Yelp, where only 20 records at a time are retrived:  (20, 17)\n"
     ]
    }
   ],
   "source": [
    "# API about bookstores in San Francisco, California\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# API authenticaion: https://www.yelp.com/developers/v3/manage_app \n",
    "# API endpoint: https://api.yelp.com/v3/businesses/search\n",
    "    # parameters we want: term, location\n",
    "    # Dictionary with authentication info\n",
    "\n",
    "api_url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "\n",
    "# Get the Yelp API key from the .env file\n",
    "api_key = os.environ.get(\"YELP_API_KEY\")\n",
    "\n",
    "# Create dictionary with authentication info\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer {}\".format(api_key)\n",
    "}\n",
    "\n",
    "# Create dictionary to query API for cafes in NYC\n",
    "parameters = {\"term\": \"cafe\",\n",
    "          \t  \"location\": \"NYC\"}\n",
    "\n",
    "# Query the Yelp API with headers and params set\n",
    "response = requests.get(api_url,\n",
    "                headers=headers,\n",
    "                params=parameters)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Extract JSON data from response\n",
    "    data = response.json()\n",
    "\n",
    "    # Load \"businesses\" values to a dataframe and print head\n",
    "    cafes = pd.DataFrame(data[\"businesses\"])\n",
    "\n",
    "    # View the data's dtypes\n",
    "    print(cafes.dtypes)\n",
    "    print(cafes.head())\n",
    "    print(\"This is the shape of the dataframe returned by Yelp, where only 20 records at a time are retrived: \", cafes.shape)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the new shape of the dataframe returned by Yelp:  (50, 17)\n"
     ]
    }
   ],
   "source": [
    "# Now, suppose we have already loaded 50 records by having set the \"limit\": 50 in a previous time.\n",
    "# Concatenating more datasets, because Yelp only returns 20 at a time. This returns 51:100.\n",
    "parameters2 = {\"term\": \"cafe\", \n",
    "          \"location\": \"NYC\",\n",
    "          \"sort_by\": \"rating\", \n",
    "          \"limit\": 50,\n",
    "          \"offset\": 50}\n",
    "\n",
    "# Query the Yelp API with headers and params set\n",
    "response = requests.get(api_url,\n",
    "                headers=headers,\n",
    "                params=parameters2)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Extract JSON data from response\n",
    "    data = response.json()\n",
    "\n",
    "    # Load \"businesses\" values to a dataframe and print head\n",
    "    cafes = pd.DataFrame(data[\"businesses\"])\n",
    "\n",
    "    print(\"This is the new shape of the dataframe returned by Yelp: \", cafes.shape)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Json's type from the API request: <class 'dict'>\n",
      "How does the json looks like: \n",
      "businesses : [{'id': 'Uu2yJ_LoL1nTcr3Vf2Oz6g', 'alias': 'borderlands-books-san-francisco', 'name': 'Borderlands Books', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/rxMcttdR9XapCMW-56shkg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/borderlands-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 215, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.8, 'coordinates': {'latitude': 37.7696454422024, 'longitude': -122.45099043497255}, 'transactions': [], 'price': '$$', 'location': {'address1': '1740 Haight St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94117', 'country': 'US', 'state': 'CA', 'display_address': ['1740 Haight St', 'San Francisco, CA 94117']}, 'phone': '+14158248203', 'display_phone': '(415) 824-8203', 'distance': 1606.2593010382498, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'N9c6fjIX7jcuAdWZ6Rj4ZQ', 'alias': 'the-booksmith-san-francisco', 'name': 'The Booksmith', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/hndowGuVQcWTaj2uARAynQ/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/the-booksmith-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 260, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}, {'alias': 'mags', 'title': 'Newspapers & Magazines'}], 'rating': 4.4, 'coordinates': {'latitude': 37.76931, 'longitude': -122.4512485}, 'transactions': [], 'price': '$$', 'location': {'address1': '1727 Haight St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94117', 'country': 'US', 'state': 'CA', 'display_address': ['1727 Haight St', 'San Francisco, CA 94117']}, 'phone': '+14158638688', 'display_phone': '(415) 863-8688', 'distance': 1602.3212252688702, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'ngUUOEyCHdLkGnO1I5M4Vg', 'alias': 'green-apple-books-san-francisco', 'name': 'Green Apple Books', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/o4Aq5cNKR9popVVJ8_InNQ/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/green-apple-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 1422, 'categories': [{'alias': 'musicvideo', 'title': 'Music & DVDs'}, {'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.6, 'coordinates': {'latitude': 37.78315627054411, 'longitude': -122.46472269989542}, 'transactions': [], 'price': '$$', 'location': {'address1': '506 Clement St', 'address2': 'at 6th Avenue', 'address3': '', 'city': 'San Francisco', 'zip_code': '94118', 'country': 'US', 'state': 'CA', 'display_address': ['506 Clement St', 'at 6th Avenue', 'San Francisco, CA 94118']}, 'phone': '+14153872272', 'display_phone': '(415) 387-2272', 'distance': 3507.3367644293944, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'e9Vd5w1sIiPvvUznzdq_vw', 'alias': 'green-apple-books-on-the-park-san-francisco-10', 'name': 'Green Apple Books on the Park', 'image_url': 'https://s3-media4.fl.yelpcdn.com/bphoto/N8RqW4L1eNAO70-aLIBXjA/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/green-apple-books-on-the-park-san-francisco-10?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 88, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.4, 'coordinates': {'latitude': 37.7653559, 'longitude': -122.4667373}, 'transactions': [], 'price': '$$', 'location': {'address1': '1231 9th Ave', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94122', 'country': 'US', 'state': 'CA', 'display_address': ['1231 9th Ave', 'San Francisco, CA 94122']}, 'phone': '+14157425833', 'display_phone': '(415) 742-5833', 'distance': 2708.374808654912, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': '_0M70HTJujT9wL-rxEWhPg', 'alias': 'fabulosa-books-san-francisco', 'name': 'Fabulosa Books', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/h1cWMEqOWt0H-BPq94AiXg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/fabulosa-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 22, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 5.0, 'coordinates': {'latitude': 37.7612323, 'longitude': -122.43478409999932}, 'transactions': [], 'price': '$$', 'location': {'address1': '489 Castro St', 'address2': None, 'address3': '', 'city': 'San Francisco', 'zip_code': '94114', 'country': 'US', 'state': 'CA', 'display_address': ['489 Castro St', 'San Francisco, CA 94114']}, 'phone': '', 'display_phone': '', 'distance': 150.80773278197825, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'fhWINTqLgfv53qKGtOdW_A', 'alias': 'black-bird-bookstore-and-cafe-san-francisco', 'name': 'Black Bird Bookstore and Cafe', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/8_z0LzJVPCi3TrxV__Mqsw/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/black-bird-bookstore-and-cafe-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 74, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.6, 'coordinates': {'latitude': 37.762, 'longitude': -122.50675}, 'transactions': [], 'price': '$$', 'location': {'address1': '4541 Irving St', 'address2': '', 'address3': None, 'city': 'San Francisco', 'zip_code': '94122', 'country': 'US', 'state': 'CA', 'display_address': ['4541 Irving St', 'San Francisco, CA 94122']}, 'phone': '+14157425203', 'display_phone': '(415) 742-5203', 'distance': 6183.61428873935, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': '7g7upQhKEPuCnNpfmSQbBg', 'alias': 'browser-books-san-francisco', 'name': 'Browser Books', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/BLF3_hQBIcAphvQ8FyJDxg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/browser-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 137, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.2, 'coordinates': {'latitude': 37.7895899, 'longitude': -122.43428}, 'transactions': [], 'price': '$$', 'location': {'address1': '2195 Fillmore St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94115', 'country': 'US', 'state': 'CA', 'display_address': ['2195 Fillmore St', 'San Francisco, CA 94115']}, 'phone': '+14155678027', 'display_phone': '(415) 567-8027', 'distance': 3203.6464230637516, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'ip8_lbJ4CRoTAFsId3dl4Q', 'alias': 'kinokuniya-bookstore-san-francisco-san-francisco-3', 'name': 'Kinokuniya Bookstore - San Francisco', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/_80LsclQrNXG3oOPQ_0R-A/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/kinokuniya-bookstore-san-francisco-san-francisco-3?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 513, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}, {'alias': 'giftshops', 'title': 'Gift Shops'}, {'alias': 'stationery', 'title': 'Cards & Stationery'}], 'rating': 4.5, 'coordinates': {'latitude': 37.78522, 'longitude': -122.43157}, 'transactions': [], 'price': '$$', 'location': {'address1': '1581 Webster St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94115', 'country': 'US', 'state': 'CA', 'display_address': ['1581 Webster St', 'San Francisco, CA 94115']}, 'phone': '+14155677625', 'display_phone': '(415) 567-7625', 'distance': 2720.8040341590026, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'EYi_i_jQ5eQosYrl2-0Blw', 'alias': 'bound-together-books-san-francisco-3', 'name': 'Bound Together Books', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/yDu2F8_qlXckWByEUKxkEA/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/bound-together-books-san-francisco-3?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 39, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.4, 'coordinates': {'latitude': 37.77019785954254, 'longitude': -122.4447369}, 'transactions': [], 'price': '$$', 'location': {'address1': '1369 Haight St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94117', 'country': 'US', 'state': 'CA', 'display_address': ['1369 Haight St', 'San Francisco, CA 94117']}, 'phone': '+14154318355', 'display_phone': '(415) 431-8355', 'distance': 1264.9188656780573, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': '_rbF2ooLcMRA7Kh8neIr4g', 'alias': 'city-lights-booksellers-and-publishers-san-francisco', 'name': 'City Lights Booksellers & Publishers', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/tybVzt2j2aDFQUpTkoxqHg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/city-lights-booksellers-and-publishers-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 749, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.4, 'coordinates': {'latitude': 37.7975997924805, 'longitude': -122.406578063965}, 'transactions': [], 'price': '$$', 'location': {'address1': '261 Columbus Ave', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94133', 'country': 'US', 'state': 'CA', 'display_address': ['261 Columbus Ave', 'San Francisco, CA 94133']}, 'phone': '+14153628193', 'display_phone': '(415) 362-8193', 'distance': 4851.8241078398705, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'KRhmAZrHc8DGxYWQEi9JsQ', 'alias': 'dog-eared-books-san-francisco', 'name': 'Dog Eared Books', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/CnDZExVaehCl_CNyV2D0nQ/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/dog-eared-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 295, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.3, 'coordinates': {'latitude': 37.7583689242601, 'longitude': -122.4213013798}, 'transactions': [], 'price': '$$', 'location': {'address1': '900 Valencia St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94110', 'country': 'US', 'state': 'CA', 'display_address': ['900 Valencia St', 'San Francisco, CA 94110']}, 'phone': '+14152821901', 'display_phone': '(415) 282-1901', 'distance': 1358.1026758620612, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'sdIatTFoAAPg8MZHCbrADg', 'alias': 'bookshop-west-portal-san-francisco', 'name': 'Bookshop West Portal', 'image_url': 'https://s3-media4.fl.yelpcdn.com/bphoto/Qi7G0FcbY681wcNie41_OA/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/bookshop-west-portal-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 137, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.4, 'coordinates': {'latitude': 37.74015, 'longitude': -122.46696}, 'transactions': [], 'price': '$$', 'location': {'address1': '80 West Portal Ave', 'address2': None, 'address3': '', 'city': 'San Francisco', 'zip_code': '94127', 'country': 'US', 'state': 'CA', 'display_address': ['80 West Portal Ave', 'San Francisco, CA 94127']}, 'phone': '+14155648080', 'display_phone': '(415) 564-8080', 'distance': 3534.5496916635147, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'Pi8PKZToXw2wqvkOM3Po0Q', 'alias': 'my-favorite-san-francisco-4', 'name': 'My Favorite', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/sTdScYSmKThaEjVUWpJazg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/my-favorite-san-francisco-4?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 242, 'categories': [{'alias': 'stationery', 'title': 'Cards & Stationery'}, {'alias': 'baby_gear', 'title': 'Baby Gear & Furniture'}, {'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.0, 'coordinates': {'latitude': 37.7639799, 'longitude': -122.46446}, 'transactions': [], 'price': '$$', 'location': {'address1': '601 Irving St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94122', 'country': 'US', 'state': 'CA', 'display_address': ['601 Irving St', 'San Francisco, CA 94122']}, 'phone': '+14152425540', 'display_phone': '(415) 242-5540', 'distance': 2476.1066500149955, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'BG5xISBIu-hpOAOHeZueKQ', 'alias': 'books-inc-san-francisco-15', 'name': 'Books Inc', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/_942yo9cy7Cg9gyP_N68nQ/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/books-inc-san-francisco-15?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 69, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.2, 'coordinates': {'latitude': 37.786338, 'longitude': -122.451783}, 'transactions': [], 'price': '$$', 'location': {'address1': '3515 California St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94118', 'country': 'US', 'state': 'CA', 'display_address': ['3515 California St', 'San Francisco, CA 94118']}, 'phone': '+14152213666', 'display_phone': '(415) 221-3666', 'distance': 3137.0777876856405, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'cG9vd88YybcnGqa3dO69iQ', 'alias': 'argonaut-book-shop-san-francisco', 'name': 'Argonaut Book Shop', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/E3qPACi8XLZ28hlk3W5UMA/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/argonaut-book-shop-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 10, 'categories': [{'alias': 'usedbooks', 'title': 'Used Bookstore'}], 'rating': 5.0, 'coordinates': {'latitude': 37.78879, 'longitude': -122.41333}, 'transactions': [], 'price': '$$', 'location': {'address1': '786 Sutter St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94109', 'country': 'US', 'state': 'CA', 'display_address': ['786 Sutter St', 'San Francisco, CA 94109']}, 'phone': '+14154749067', 'display_phone': '(415) 474-9067', 'distance': 3707.999356265622, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'QLnYFOcuDuH1FyvA6VekGg', 'alias': 'books-and-bookshelves-san-francisco', 'name': 'Books & Bookshelves', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/ksLO6R_XPnstN-Tyhr1vPg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/books-and-bookshelves-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 76, 'categories': [{'alias': 'furniture', 'title': 'Furniture Stores'}, {'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.6, 'coordinates': {'latitude': 37.7676175, 'longitude': -122.4311688}, 'transactions': [], 'price': '$$', 'location': {'address1': '99 Sanchez St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94114', 'country': 'US', 'state': 'CA', 'display_address': ['99 Sanchez St', 'San Francisco, CA 94114']}, 'phone': '+14156213761', 'display_phone': '(415) 621-3761', 'distance': 879.3860893296346, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'VOlDLrbzFGuPVf39DSd63w', 'alias': 'forest-books-san-francisco-2', 'name': 'Forest Books', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/TxXvDNsNibt7c2ldD8kzmw/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/forest-books-san-francisco-2?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 26, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.4, 'coordinates': {'latitude': 37.786266, 'longitude': -122.429726}, 'transactions': [], 'price': '$$', 'location': {'address1': '1748 Buchanan St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94115', 'country': 'US', 'state': 'CA', 'display_address': ['1748 Buchanan St', 'San Francisco, CA 94115']}, 'phone': '+14155638302', 'display_phone': '(415) 563-8302', 'distance': 2881.9046862761516, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'oml49XIewZrlbd7srw43yA', 'alias': 'mai-do-san-francisco-san-francisco', 'name': 'Mai Do - San Francisco', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/gGuBS9c9VYGxJrGuKxhM8w/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/mai-do-san-francisco-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 302, 'categories': [{'alias': 'stationery', 'title': 'Cards & Stationery'}, {'alias': 'artsupplies', 'title': 'Art Supplies'}, {'alias': 'giftshops', 'title': 'Gift Shops'}], 'rating': 4.2, 'coordinates': {'latitude': 37.78522, 'longitude': -122.43157}, 'transactions': [], 'price': '$$$', 'location': {'address1': '1581 Webster St', 'address2': 'Ste 180, Ste 218', 'address3': '', 'city': 'San Francisco', 'zip_code': '94115', 'country': 'US', 'state': 'CA', 'display_address': ['1581 Webster St', 'Ste 180, Ste 218', 'San Francisco, CA 94115']}, 'phone': '+14155678901', 'display_phone': '(415) 567-8901', 'distance': 2720.8040341590026, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 'PlGsGIWwHqJ7bb28Zl9UDg', 'alias': 'globus-books-san-francisco', 'name': 'Globus Books', 'image_url': 'https://s3-media3.fl.yelpcdn.com/bphoto/aK_S45-KKshRmMCWx_qnNg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/globus-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 8, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 5.0, 'coordinates': {'latitude': 37.77755, 'longitude': -122.46246}, 'transactions': [], 'price': '$$', 'location': {'address1': '332 Balboa St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94118', 'country': 'US', 'state': 'CA', 'display_address': ['332 Balboa St', 'San Francisco, CA 94118']}, 'phone': '+14156684723', 'display_phone': '(415) 668-4723', 'distance': 2937.323112910807, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}, {'id': 's5NsptQPippNuZ6gJyCqCA', 'alias': 'books-inc-san-francisco-16', 'name': 'Books Inc', 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/a3DXlSHzQKz3WnL9QMWFMg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/books-inc-san-francisco-16?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 128, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.2, 'coordinates': {'latitude': 37.80001, 'longitude': -122.44029}, 'transactions': [], 'price': '$$', 'location': {'address1': '2251 Chestnut St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94123', 'country': 'US', 'state': 'CA', 'display_address': ['2251 Chestnut St', 'San Francisco, CA 94123']}, 'phone': '+14159313633', 'display_phone': '(415) 931-3633', 'distance': 4363.560372196896, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}]\n",
      "total : 207\n",
      "region : {'center': {'longitude': -122.43644714355469, 'latitude': 37.76089938976322}}\n",
      "Json keys has 3 keys::  dict_keys(['businesses', 'total', 'region'])\n",
      "Note that the 'businesses' value is of a list type:  <class 'list'>\n",
      "However, it is a dictionary inside a list: \n",
      "<class 'list'>\n",
      "There are,  20 elements in the 'businesses' key.\n",
      "Accessing the first element, which is of type:  <class 'dict'>\n",
      "{'id': 'Uu2yJ_LoL1nTcr3Vf2Oz6g', 'alias': 'borderlands-books-san-francisco', 'name': 'Borderlands Books', 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/rxMcttdR9XapCMW-56shkg/o.jpg', 'is_closed': False, 'url': 'https://www.yelp.com/biz/borderlands-books-san-francisco?adjust_creative=RraRAWZZ1IgIuxDvaATISQ&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=RraRAWZZ1IgIuxDvaATISQ', 'review_count': 215, 'categories': [{'alias': 'bookstores', 'title': 'Bookstores'}], 'rating': 4.8, 'coordinates': {'latitude': 37.7696454422024, 'longitude': -122.45099043497255}, 'transactions': [], 'price': '$$', 'location': {'address1': '1740 Haight St', 'address2': '', 'address3': '', 'city': 'San Francisco', 'zip_code': '94117', 'country': 'US', 'state': 'CA', 'display_address': ['1740 Haight St', 'San Francisco, CA 94117']}, 'phone': '+14158248203', 'display_phone': '(415) 824-8203', 'distance': 1606.2593010382498, 'attributes': {'business_temp_closed': None, 'open24_hours': None, 'waitlist_reservation': None}}\n",
      "Accessing the 'categories' key of the first item in the 'businesses' key:  [{'alias': 'bookstores', 'title': 'Bookstores'}]\n"
     ]
    }
   ],
   "source": [
    "# Nested JSONs\n",
    "\n",
    "# Example: The Yelp API response data is nested. \n",
    "# The idea is to look at bookstores in San Francisco.\n",
    "# Your job is to flatten out the next level of data in the coordinates and location columns.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Set up headers, parameters, and API endpoint\n",
    "api_url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "\n",
    "# Get the Yelp API key from the .env file\n",
    "api_key = os.environ.get(\"YELP_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"YELP_API_KEY environment variable is not set!\")\n",
    "    # You can handle this case however you want, such as exiting the program\n",
    "else:\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(api_key)}\n",
    "    params = {\"term\": \"bookstore\", \n",
    "              \"location\": \"San Francisco\"}\n",
    "\n",
    "# Make the API call and extract the JSON data\n",
    "response = requests.get(api_url, headers=headers, params=params)\n",
    "bookstore_data_dict = response.json()\n",
    "\n",
    "print(\"This is the Json's type from the API request:\", type(bookstore_data_dict))\n",
    "print(\"How does the json looks like: \")\n",
    "for key in bookstore_data_dict.keys():\n",
    "    print(key, \":\", bookstore_data_dict[key])\n",
    "print(\"Json keys has 3 keys:: \", bookstore_data_dict.keys())\n",
    "print(\"Note that the 'businesses' value is of a list type: \", type(bookstore_data_dict[\"businesses\"]))\n",
    "print(\"However, it is a dictionary inside a list: \")\n",
    "biz_bookstore_data_list = bookstore_data_dict[\"businesses\"]\n",
    "print(type(biz_bookstore_data_list))\n",
    "print(\"There are, \", len(biz_bookstore_data_list), \"elements in the 'businesses' key.\")\n",
    "print(\"Accessing the first element, which is of type: \", type(biz_bookstore_data_list[0]))\n",
    "print(biz_bookstore_data_list[0])\n",
    "print(\"Accessing the 'categories' key of the first item in the 'businesses' key: \", biz_bookstore_data_list[0]['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      " ['id', 'alias', 'name', 'image_url', 'is_closed', 'url', 'review_count', 'categories', 'rating', 'transactions', 'price', 'phone', 'display_phone', 'distance', 'coordinates_latitude', 'coordinates_longitude', 'location_address1', 'location_address2', 'location_address3', 'location_city', 'location_zip_code', 'location_country', 'location_state', 'location_display_address', 'attributes_business_temp_closed', 'attributes_open24_hours', 'attributes_waitlist_reservation']\n",
      "The coordinates_latitude column: \n",
      " 0    37.769645\n",
      "1    37.769310\n",
      "Name: coordinates_latitude, dtype: float64\n",
      "However, note that 'categories' is still nested: \n",
      " 0     [{'alias': 'bookstores', 'title': 'Bookstores'}]\n",
      "1    [{'alias': 'bookstores', 'title': 'Bookstores'...\n",
      "Name: categories, dtype: object\n",
      "This is the alias from the 'categories' value within the 'businesses' value: \n",
      " bookstores\n",
      "This is the alias from the 'businesses' value: \n",
      " borderlands-books-san-francisco\n",
      "Now, printing alias (businesses key), alias (categories key) and coordinates_latitude (already flattened):\n",
      "alias (businesses key):  borderlands-books-san-francisco\n",
      "alias (categories key):  bookstores\n",
      "coordinates_latitude (already flattened) 37.7696454422024\n",
      "-------\n",
      "Flattened dataframe columns (based on categories): \n",
      " ['alias', 'title', 'biz_name', 'biz_alias', 'biz_rating', 'biz_coordinates_latitude', 'biz_coordinates_longitude']\n",
      "                         biz_alias       alias biz_coordinates_latitude\n",
      "0  borderlands-books-san-francisco  bookstores                37.769645\n",
      "Notice that both the first json ( using json_normalize() ) and the flattened json based on categories are the same thing. However, the flattened is more denormalized (more duplicated in some columns)\n"
     ]
    }
   ],
   "source": [
    "# So, there are many jsons nested inside jsons. We need to flatten them. \n",
    "import numpy as np\n",
    "\n",
    "# Flatten business data into a dataframe, replace separator\n",
    "bookstore_data_df = pd.json_normalize(bookstore_data_dict[\"businesses\"], sep = '_')\n",
    "\n",
    "# View the data\n",
    "print(\"Dataframe columns: \\n\", list(bookstore_data_df.columns))\n",
    "print(\"The coordinates_latitude column: \\n\", bookstore_data_df[\"coordinates_latitude\"].head(2))\n",
    "print(\"However, note that 'categories' is still nested: \\n\", bookstore_data_df['categories'].head(2))\n",
    "print(\"This is the alias from the 'categories' value within the 'businesses' value: \\n\", bookstore_data_df['categories'][0][0][\"alias\"])\n",
    "print(\"This is the alias from the 'businesses' value: \\n\", bookstore_data_df['alias'][0])\n",
    "print(\"Now, printing alias (businesses key), alias (categories key) and coordinates_latitude (already flattened):\" )\n",
    "print(\"alias (businesses key): \", bookstore_data_df['alias'][0])\n",
    "print(\"alias (categories key): \", bookstore_data_df['categories'][0][0][\"alias\"])\n",
    "print(\"coordinates_latitude (already flattened)\", bookstore_data_df['coordinates_latitude'][0])\n",
    "print(\"-------\")\n",
    "\n",
    "# Load other business attributes and set meta prefix\n",
    "bookstore_data_flat_df = pd.json_normalize(data[\"businesses\"],\n",
    "                            sep=\"_\",\n",
    "                    \t\trecord_path=\"categories\", # this sets the \n",
    "                    \t\tmeta=['name', \n",
    "                                  'alias',  \n",
    "                                  'rating',\n",
    "                          \t\t  ['coordinates', 'latitude'],   #this will flatten coordinates\n",
    "                          \t\t  ['coordinates', 'longitude']], #this will flatten coordinates\n",
    "                    \t\tmeta_prefix=\"biz_\")\n",
    "\n",
    "# View the data\n",
    "print(\"Flattened dataframe columns (based on categories): \\n\", list(bookstore_data_flat_df.columns))\n",
    "print(bookstore_data_flat_df[[\"biz_alias\", \"alias\", \"biz_coordinates_latitude\"]].head(1))\n",
    "print(\"Notice that both the first json ( using json_normalize() ) and the flattened json based on categories are the same thing. However, the flattened is more denormalized (more duplicated in some columns)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting from a (Relational) Database\n",
    "* Step 1: Connect to a database (SQLAlchemy)\n",
    "    * Create a Database Engine to handle database connections: create_engine ()\n",
    "* Step 2: Query the database (SQL or Pandas)\n",
    "    * pd.read_sql(sql_query, engine): to load in data from a database\n",
    "\n",
    "* Databases examples:\n",
    "    * SQLite\n",
    "    * Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 0: SQLAlchemy & Pandas\n",
    "* Getting the full data\n",
    "* Getting partial data with SQL refinements (example: SELECT DISTINCT, WHERE, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlalchemy's create_engine() function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "# View the tables in the database\n",
    "print(engine.table_names())\n",
    "    # ['boro_census', 'hpd311calls', 'weather']\n",
    "# Load hpd311calls without any SQL\n",
    "hpd_calls = pd.read_sql('hpd311calls', engine) #load the hpd311calls table by name (without any SQL) into a pandas dataframe\n",
    "\n",
    "# View the first few rows of data\n",
    "print(hpd_calls.head())\n",
    "\n",
    "# Create a SQL query to load the entire weather table\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "  FROM weather;\n",
    "\"\"\"\n",
    "\n",
    "# Load weather with the SQL query\n",
    "weather = pd.read_sql(query, engine) #load the weather table by a SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Here we use Pandas & SQLAlchemy & Faker to ingest fake data into the Postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['table_test']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>2024-04-29 09:54:23.833128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>2992</td>\n",
       "      <td>2024-04-29 09:54:23.833128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>880</td>\n",
       "      <td>2024-04-29 09:54:23.833128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>5607</td>\n",
       "      <td>2024-04-29 09:54:23.833128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>5471</td>\n",
       "      <td>2024-04-29 09:54:23.833128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  amount                 created_at\n",
       "0      192     192 2024-04-29 09:54:23.833128\n",
       "1      138    2992 2024-04-29 09:54:23.833128\n",
       "2      120     880 2024-04-29 09:54:23.833128\n",
       "3       31    5607 2024-04-29 09:54:23.833128\n",
       "4       98    5471 2024-04-29 09:54:23.833128"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the SQLAlchemy package to access an postgres database\n",
    "\n",
    "# We start by importing the create_engine function.\n",
    "    # This engine fires up a SQL engine that will communicates out SQL queries to the database \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from faker import Faker\n",
    "\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine('postgresql://myuser:mypassword@postgres/mydatabase')\n",
    "\n",
    "# Checking the table names within the database\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names(schema=\"schema_test\")) # recall that postgres prefer lower case for names \n",
    "\n",
    "# Connecting to the engine and executing a SELECT query\n",
    "with engine.connect() as conn:\n",
    "\n",
    "    faker = Faker('en_US')\n",
    "\n",
    "    # Insert fake data\n",
    "    for i in range(10):\n",
    "        test_id = faker.random_int(min=1, max=200)\n",
    "        amount = faker.random_int(min=100, max=10000)\n",
    "        #created_at: recall that the created_at is defined in the init.sql\n",
    "        #insert_query = text(f\"INSERT INTO SCHEMA_TEST.TABLE_TEST (test_id, amount) VALUES ({test_id}, {amount})\")\n",
    "        insert_query = text(\"INSERT INTO SCHEMA_TEST.TABLE_TEST (test_id, amount) VALUES (:test_id, :amount)\")\n",
    "        conn.execute(insert_query, {\"test_id\": test_id, \"amount\": amount})\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit() # committing refers to finalizing and applying the changes made within a transaction to the database.\n",
    "\n",
    "    # Fetch and print the table after inserting the data\n",
    "    select_query = text(\"SELECT * FROM SCHEMA_TEST.TABLE_TEST\")\n",
    "    result = conn.execute(select_query) # Created a SQLAlchemy object that is assigned to the result variable\n",
    "    df = pd.DataFrame(result.fetchall()) # Fetches all rows\n",
    "    df.columns = result.keys() # set the dataframe column names\n",
    "    # Print the table after inserting the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Here we use Pandas & SQLAlchemy & Faker to ingest fake data into the Postgres database, but quicker at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['table_test']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>1909</td>\n",
       "      <td>2024-04-15 14:50:40.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>4832</td>\n",
       "      <td>2024-04-15 14:50:40.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>1485</td>\n",
       "      <td>2024-04-15 14:50:40.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>929</td>\n",
       "      <td>2024-04-15 14:50:40.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>1693</td>\n",
       "      <td>2024-04-15 14:50:40.478758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  amount                 created_at\n",
       "0      200    1909 2024-04-15 14:50:40.478758\n",
       "1      198    4832 2024-04-15 14:50:40.478758\n",
       "2      173    1485 2024-04-15 14:50:40.478758\n",
       "3      174     929 2024-04-15 14:50:40.478758\n",
       "4       91    1693 2024-04-15 14:50:40.478758"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the SQLAlchemy package to access an postgres database, but with pandas at the end to query it\n",
    "\n",
    "# We start by importing the create_engine function.\n",
    "    # This engine fires up a SQL engine that will communicates out SQL queries to the database \n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine('postgresql://myuser:mypassword@postgres/mydatabase')\n",
    "\n",
    "# Checking the table names within the database\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names(schema=\"schema_test\")) # recall that postgres prefer lower case for names \n",
    "\n",
    "# Connecting to the engine and executing a SELECT query\n",
    "with engine.connect() as conn:\n",
    "\n",
    "    faker = Faker('en_US')\n",
    "\n",
    "    # Insert fake data\n",
    "    for i in range(10):\n",
    "        test_id = faker.random_int(min=1, max=200)\n",
    "        amount = faker.random_int(min=100, max=10000)\n",
    "        #created_at: recall that the created_at is defined in the init.sql\n",
    "        #insert_query = text(f\"INSERT INTO SCHEMA_TEST.TABLE_TEST (test_id, amount) VALUES ({test_id}, {amount})\")\n",
    "        insert_query = text(\"INSERT INTO SCHEMA_TEST.TABLE_TEST (test_id, amount) VALUES (:test_id, :amount)\")\n",
    "        conn.execute(insert_query, {\"test_id\": test_id, \"amount\": amount})\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit() # committing refers to finalizing and applying the changes made within a transaction to the database.\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM SCHEMA_TEST.TABLE_TEST\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Here we use Pandas & urllib to ingest CSV data from an URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Here we ingest data from an URL with HTTP requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head><title>Just a moment...</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"><meta name=\"robots\" content=\"noindex,nofollow\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><style>*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .big-button,body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .big-button,body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .big-button,body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width <= 720px){.main-content{margin-top:4rem}.heading-favicon{height:1.5rem;width:1.5rem}}.footer,.main-content{padding-left:1.5rem;padding-right:1.5rem}.main-wrapper{align-items:center;display:flex;flex:1;flex-direction:column}.font-red{color:#b20f03}.spacer{margin:2rem 0}.h1{font-size:2.5rem;font-weight:500;line-height:3.75rem}.h2{font-weight:500}.core-msg,.h2{font-size:1.5rem;line-height:2.25rem}.body-text,.core-msg{font-weight:400}.body-text{font-size:1rem;line-height:1.25rem}@media (width <= 720px){.h1{font-size:1.5rem;line-height:1.75rem}.h2{font-size:1.25rem}.core-msg,.h2{line-height:1.5rem}.core-msg{font-size:1rem}}#challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+);padding-left:34px}#challenge-error-text,#challenge-success-text{background-repeat:no-repeat;background-size:contain}#challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=);padding-left:42px}.text-center{text-align:center}.big-button{border:.063rem solid #0051c3;border-radius:.313rem;font-size:.875rem;line-height:1.313rem;padding:.375rem 1rem;transition-duration:.2s;transition-property:background-color,border-color,color;transition-timing-function:ease}.big-button:hover{cursor:pointer}.captcha-prompt:not(.hidden){display:flex}@media (width <= 720px){.captcha-prompt:not(.hidden){flex-wrap:wrap;justify-content:center}}.pow-button{background-color:#0051c3;color:#fff;margin:2rem 0}.pow-button:hover{background-color:#003681;border-color:#003681;color:#fff}.footer{font-size:.75rem;line-height:1.125rem;margin:0 auto;max-width:60rem;width:100%}.footer-inner{border-top:1px solid #d9d9d9;padding-bottom:1rem;padding-top:1rem}.clearfix:after{clear:both;content:\"\";display:table}.clearfix .column{float:left;padding-right:1.5rem;width:50%}.diagnostic-wrapper{margin-bottom:.5rem}.footer .ray-id{text-align:center}.footer .ray-id code{font-family:monaco,courier,monospace}.core-msg,.zone-name-title{overflow-wrap:break-word}@media (width <= 720px){.diagnostic-wrapper{display:flex;flex-wrap:wrap;justify-content:center}.clearfix:after{clear:none;content:none;display:initial;text-align:center}.column{padding-bottom:2rem}.clearfix .column{float:none;padding:0;width:auto;word-break:keep-all}.zone-name-title{margin-bottom:1rem}}.loading-spinner{height:76.391px}.lds-ring{display:inline-block;position:relative}.lds-ring,.lds-ring div{height:1.875rem;width:1.875rem}.lds-ring div{animation:lds-ring 1.2s cubic-bezier(.5,0,.5,1) infinite;border:.3rem solid transparent;border-radius:50%;border-top-color:#313131;box-sizing:border-box;display:block;position:absolute}.lds-ring div:first-child{animation-delay:-.45s}.lds-ring div:nth-child(2){animation-delay:-.3s}.lds-ring div:nth-child(3){animation-delay:-.15s}@keyframes lds-ring{0%{transform:rotate(0)}to{transform:rotate(1turn)}}@media screen and (-ms-high-contrast:active),screen and (-ms-high-contrast:none){.main-wrapper,body{display:block}}</style><meta http-equiv=\"refresh\" content=\"105\"></head><body class=\"no-js\"><div class=\"main-wrapper\" role=\"main\"><div class=\"main-content\"><noscript><div id=\"challenge-error-title\"><div class=\"h2\"><span id=\"challenge-error-text\">Enable JavaScript and cookies to continue</span></div></div></noscript></div></div><script>(function(){window._cf_chl_opt={cvId: '3',cZone: \"www.datacamp.com\",cType: 'non-interactive',cNounce: '8781',cRay: '875c5f997ca503ce',cHash: '50b09eb08562c25',cUPMDTk: \"\\/teach\\/documentation?__cf_chl_tk=pRB2Tz41N8jgM1AyaAyE8FUXmgmGvVUS6zhgSS8PH0A-1713356471-0.0.1.1-1343\",cFPWv: 'b',cTTimeMs: '1000',cMTimeMs: '105000',cTplV: 5,cTplB: 'cf',cK: \"visitor-time\",fa: \"\\/teach\\/documentation?__cf_chl_f_tk=pRB2Tz41N8jgM1AyaAyE8FUXmgmGvVUS6zhgSS8PH0A-1713356471-0.0.1.1-1343\",md: \"0nAdZiX9kNPohNnvpSKsvnC3ez1NDB15tbqW39c7f00-1713356471-1.1.1.1-ZGoeyTz_2RvNKl1fg2_xR0zyFp72C8EeD65XSN1R2Hcw_HpZOLrTY.qMPslI73FXe9Gk.mQslJ2kE6mahitb6rvkwcJTW6io5vrTCwib2r5yxof83QuorG3fzt5sbQIoBrXFsUW1OIcM2jyBfaf.2zHWOGdKcbSjPrQrVAW8CWI3D4xB95xyvvN5HPrdT1l2O_nCrXdBpf7n1BImZPBh3v7QZu4Z73xAsUV6VQC_IufNcM7W8G9sbAUUltf3tXPT8BV4qlnd.mk8ycGcMHxVJ13lQDptabvmjwBr1kPpbGNo6COYEu14kVffg3V6IHLGh1bBPmhb_FsCcL13IVd.tuYlnURZERh_iTpFolFsNx8SID.x3M.tze2FOCnhOxvkWRC5jr6MrdYZlXEAjUkVcUCCsKzJ2rwNr.P7m0tklPh5dBSkpIT.d5O1rctqLZQr2P18S4H9hyjKF5HuPCpoC3rP1PA3Ea8JAD8jnuHPFtPvugGX76poYolBJvp75cu2vi7_KR8kJv4gj.iRxu3NaiudKixSOsgvqBQts3_EqaPliJFW5DTNmfy8BkY4Ar5VhsDE203ws2f0Xyo4mj6MZm2aW8ZdpYhaA1JJBkTikPSb6_vALqC5ZrT1tmq_4kreqkiaes0D8GNhDdZnYv5JpM5WHgs2JaR22SbQQyLjRotOuSzSvElTZ2vieHaL5FQCqdKkvzUfEtxBSI5mwdNuS5.vByUAHv_8xD.iekDLHvWqJx2HviUg28SHlwEINtmTfnXGUPZEPllq_rO6vqVOlR4.6QPWPzejRfZbIft0qJMZpLKvTCZu4F0An_q_mG4Bq6wacOegbnYvHE9_G.TRySnilhBAtykPS5i.6tQIqUQEYiITu6QlUD0OO9.6EBgmOCRuwJ5BwNhL5Bok88DQ_ORzQz1QvpvWcykjZWQydFb1CzDmotpEclTIGqCl6fa2I_B5QUQFLlTj1NAvVJU1kEz5tGfYLAqxKv5HhIrICKLzzy0zNNLo7Nve_sYvw4on2vW6VlufCBvGJoFnLJmLp9tlWncbCL6MNIuMRwQ9ikd4lx4WS98RTwgqU2Rpp0jE66sf896XExodshOAhP_D3vPY6gKWjKrHvv9ZW0f21.8ODkdZ7gixNnloOva4HSy1rL84GKLS6gASXGEvuQmx_0OqeiOCY39IPbT01ehBuVnhu3mZoV1n6y3c4kiVcFSp0zkOWVfu_5BXbWP_aHCMTapnrA72IFWqMNGPQ6q3lmND3SHSO.1WJw1CugFE0lKh\",mdrd: \"qwUZJe7XjqKntIsuQQMCeDR_zXASURzhb_qUPIWJ.jw-1713356471-1.1.1.1-7PhOGVF61bV.aYGo2Ht1wa917P1gQMX5FD8OBTF8wmBp_qzUQG7eMkQn.U6H2RPfJ4MBNC5j1t_sRhDfBSleUPGo.GZccaAuIu8YrdKVR6Jt63r_9uixELiEJsT5WgqCdcLlXaJq3HzD1a3uoTf.NfgeBOGv0TizW_ZZtyW9b.pwhwEOAWygCaoGqdTeBUr0TApwBLdATAKSYLzo_fkWNH3vdJ_ESo.mqUl33C5bWrwF83CK8NSFW3ibzvUBiOBiHth2MDuVWPXlWMiPcMrIiPK__tfSPzHaaQy6AmNbS9KxfmTK4FYZIyblTqtf7MV.tFHewtrT8mB_KA0rW4c13IPJI90SNhZcx0NqBeQIthitjIwFlhgcCVvR1HZKOGs2vNlrPLgUqq16.xTHAcT6IMc.KB9z.Oz9_Q7nfm8dd9xgFfitzRzQLnvuFaDhz0llUg60p4MF.y1Y69jlXlwaYO92KFVCyKrNX5IAWYDnbt_uRjB7brvnT7BOdXZtqfFynWVe0PGkqXYti_9N5P0ZCY29y5yklH5De4wK7BUUA8QJkLo9kLnsTj_akIrb2iOdqgU1yv.vpOZi2o1D4RVQdCngbqF00ZL3rY1FR8EvBds5TAxAttIULkG.msnTsrK78E1WLU8NBmoKWIushpyV97XDSepLNydU.0po5mANcZLQqqVE9gUO3R9wtJmFcvdVIjbdQi4bL1AsrCe56CINvybml7alEoqbHnbqn0YA1FqhO5OF27rrXxaVRRyGgHsdvwuazm6.zjC4w3rFsgYHuwYFgnildvmeocpsmvlTQFD8drSks.uoSGyh53JbeBuOkJEK.EME0wfcU8AQrCLqat59W1QSmISAN7woFWwfjRbiJOd7ySnAogTBrkAux0lteDmc.suVrFB57hwsbsTPEGiSvcu3VjNtbjLcVSuGayAEGLP49ugEmmqnNQ9z7CH6QoxvUd_zFcKz4TBXQmB2nN6dCpvzOxp91t1vDoukGP3OZRaut87hB3VALyEvowqDFyLWtEylD4rb3BMuQMk13EplJkZQus.JoXjSG.x3cCba1OSet6MDrJEtN.v6j.7Ss7vQYKLMz47vVgPduSA8DBOaRCuXUdcDyGR9Ss8EQeWDKASEvE_ivJv7bWp_S.0v.9jsWUQmFmdS8SvQAeG4YfPsy.mM1Ngpf2BUDvfUoroOel9CgjBHC1y2dtODbzDt2.B8kT8zwETWYhwEemQ5LZ7E6x70b0J0wfXBvvabE.KklWOFdyuH9VKIxyRU2wmMvVKifL_OGIhLVgzXZ08dQrMPZ1VOTXZGNCNfD2bbWdNo8TtwMZZHvwH7s9K3u.rioqnguVODCb3EopHblOTGImEpb93x5lqyoj6fjEYDKb.JOMnNm4UO4s7Fot8YxQSmXywaosHQ_6o0cbJwE19FFFoWVDU00xUzUQ3CqCOEpEWNkvXsU7ldSYQOLnbeVyujm5hmyWusUsBQ1iHIQzjpQL80ZcIvCAB22mFNd01S8rpLDzh2D76Nd427OuxvJcUdlJvM8tpRYnzfKRQrnc3ZV8LRDorAhsMytvbi1Hs0I0YlFntHFdGlusI_sshtXOKXwiqLIcgQX5p5b39jNRHKl7zuaWfNjaOeWsVqBq5Ht_vBDoLVWsJx8JF_Rgliq65BHjPFMSLy3wFF8TsfJhNkUyvCBUZNwumqToQYCop0VTaCUxBt97S6VpdtiR58rCNfhsmT6yriFsEL8U6SJgjqIdgMbxF4vhGAve66YAN16eCVBbzt8xEFn_0RwHfiynCt9pHKBTkN4lpW2ExREerQpsi1VPbjv2yI6Sb2tiroy3jJPbzlMXI1GI2Lqw7OWiuqnWe7ZFNCxpkk83VnHmIj_TLpKaJ5Ibg.UNN92qbv06dMC57Ufytj4ai7avglAZClFx6OTJA0TsCegW.d6JWeQ0xIqDoiXDP6xxfrlxydXWHcJ5rUiWFDCZ6FnJvU8FjlqTiNQuDDaqnSx5CZ9NbXK_a5srernxja2NNhfgRqtxibeLHOMX3SAkvFWyWqmb7UJe_XFnArllfOOByIDIqhH0cd1nMJRHJs1PkuEN58NXYmZ9rIr2MqCu28lSa2PEpJm4KPSSA_kgOS.qO8wTFZcNHI5QngHcHAMFUaWsBiVNK.ovY_YlI67rc_tbTg4ZGXeA7WuraROMq9ApY8HTIcMHjcxoches8.ibobx2OYs5Oz43DrncMotw.0mCoG0Jwvobtef3WtDOYdPein1itdb3rD0cLN6865Ez69epccsRwxXcVJi5ql44h6E8x_.gAN\",cRq: {ru: 'aHR0cHM6Ly93d3cuZGF0YWNhbXAuY29tL3RlYWNoL2RvY3VtZW50YXRpb24=',ra: 'cHl0aG9uLXJlcXVlc3RzLzIuMzEuMA==',rm: 'R0VU',d: 'f7BiNZIGFPWvlphihT2Q7Zk1UiBbv5H0gCqI+bm+KvYa7JTJPJ1p5hzWtGbCUPyAPIi/bKZIV+0b5ySoaz1LahICQUWxwINs8RkDVBQd0h3NpSnJJqHlWfehuWPUBCtPxkjwoSShU5SnUSSsLBAtDPVbtePRvmCLBwYWgjvND/krU4+EeMER2/9mizzuKIm7synrDvfrx1gV+fqQ7TemfaKyWaC0Iao57JydODvAMDm2pVD7707AwjfcZGQO8PmqSjXR7VRCC26eRlPdnOPsxa4BHTYfPJBA1F+r6b6mRlKrxYzJ03Rwg9YPNRuu3POF9DC/xjsQ7kgVp2l3otS/aXqw8ydFL1B2xAizcTNSSKYYHO0jfENm9THV3elZXXdlP0jV/SdI90p/SS+ErM5gkzKiYEd4cib3PNCQOwVr0jKkx8nlsIC0hh1cbFnougVJZNfgyjbkh7WRWLa4Ncm2a8LwDZyktqopvp0Dw+zs2Kck7WfkcJZ21e2BE3S7GdCOW7b5zmbZKF74VrvouznRvgsVE51oW1O9p6jivUQywTgQxDWjTgVMa8tlAMEF7Iyqr7HbE25+/LDbJ5TdEjZ1mDG28jm5dxQhWGnJ7TSJWPQ=',t: 'MTcxMzM1NjQ3MS4yODUwMDA=',cT: Math.floor(Date.now() / 1000),m: 'nZbZN7pfyknTa+YpeMcDTRTgCvAPKgrsQEmfnE/FHkE=',i1: 'eNh57149V0N4HRpb0bQJWA==',i2: 'TzXB6/Cbk76uO/vlNRmpjw==',zh: 'hzfiqo9hugT9sHeHQ1zy81NCL/S0295H0+GuRnkSV9o=',uh: 'YE9XOpG5TeHmhA1zfs5mxC8CrRZzq2a/+r+OU7dliYQ=',hh: 'rAZnIHiyrNuZ60h9aAZNML8izDilqmOSNuCtac1WqPs=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=875c5f997ca503ce';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/teach\\/documentation?__cf_chl_rt_tk=pRB2Tz41N8jgM1AyaAyE8FUXmgmGvVUS6zhgSS8PH0A-1713356471-0.0.1.1-1343\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());</script></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# Packages the request, send the request and catch the response r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Here we Scrape the web using BeautifulSoup and HTTP requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "images/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "Resume.html\n",
      "https://docs.python.org\n",
      "https://github.com/python/cpython/issues\n",
      "https://discuss.python.org\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks)\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Here we Ingest data from APIs and JSONs, anonymously (without an account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  The Social Network\n",
      "Year:  2010\n",
      "Rated:  PG-13\n",
      "Released:  01 Oct 2010\n",
      "Runtime:  120 min\n",
      "Genre:  Biography, Drama\n",
      "Director:  David Fincher\n",
      "Writer:  Aaron Sorkin, Ben Mezrich\n",
      "Actors:  Jesse Eisenberg, Andrew Garfield, Justin Timberlake\n",
      "Plot:  As Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, he is sued by the twins who claimed he stole their idea and by the co-founder who was later squeezed out of the business.\n",
      "Language:  English, French\n",
      "Country:  United States\n",
      "Awards:  Won 3 Oscars. 173 wins & 187 nominations total\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Ratings:  [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '96%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Metascore:  95\n",
      "imdbRating:  7.8\n",
      "imdbVotes:  754,796\n",
      "imdbID:  tt1285016\n",
      "Type:  movie\n",
      "DVD:  05 Jun 2012\n",
      "BoxOffice:  $96,962,694\n",
      "Production:  N/A\n",
      "Website:  N/A\n",
      "Response:  True\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])\n",
    "\n",
    "# or this: Print each key-value pair in json_data\n",
    "# for k, v in json_data.items():\n",
    "#     print(k + ': ', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: Here we Ingest data from APIs and nested JSONs, anonymously (without an account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\">\n",
      "<p class=\"mw-empty-elt\">\n",
      "\n",
      "</p>\n",
      "<p><b>Pizza</b> (<span></span> <i title=\"English pronunciation respelling\"><span>PEET</span>-s</i>, <span>Italian:</span> <span lang=\"it-Latn-fonipa\">[pittsa]</span>; <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1177148991\"><span>Neapolitan:</span> <span lang=\"nap-Latn-fonipa\">[pitts]</span>) is a dish of Italian origin consisting of a flat base of leavened wheat-based dough topped with tomato, cheese, and other ingredients, baked at a high temperature, traditionally in a wood-fired oven.</p><p>The term <i>pizza</i> was first recorded in the year 997 AD, in a Latin manuscript from the southern Italian town of Gaeta, in Lazio, on the border with Campania. Raffaele Esposito is often credited for creating modern pizza in Naples. In 2009, Neapolitan pizza was registered with the European Union as a traditional speciality guaranteed dish. In 2017, the art of making Neapolitan pizza was added to UNESCO's list of intangible cultural heritage.</p><p>Pizza and its variants are among the most popular foods in the world. Pizza is sold at a variety of restaurants, including pizzerias (pizza specialty restaurants), Mediterranean restaurants, via delivery, and as street food. In Italy, pizza served in a restaurant is presented unsliced, and is eaten with the use of a knife and fork. In casual settings, however, it is typically cut into slices to be eaten while held in the hand. Pizza is also sold in grocery stores in a variety of forms, including frozen or as kits for self-assembly. They are then cooked using a home oven.\n",
      "</p><p>In 2017, the world pizza market was US$128 billion, and in the US it was $44 billion spread over 76,000 pizzerias. Overall, 13% of the U.S. population aged two years and over consumed pizza on any given day.</p>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "\n",
    "# Package the request, send the request and catch the response r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract (nested jsons)\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 8: Here we Ingest data from Twitter APIs and nested JSONs, with an account (with authentication credentials). We use Tweepy and we filter tweets for specific tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tweepy' has no attribute 'Stream'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m access_token_secret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create your Stream object with credentials\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mtweepy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStream\u001b[49m(consumer_key, consumer_secret, access_token, access_token_secret)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Filter your Stream variable\u001b[39;00m\n\u001b[1;32m     16\u001b[0m stream\u001b[38;5;241m.\u001b[39mfilter([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclinton\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrump\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msanders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcruz\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tweepy' has no attribute 'Stream'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import tweepy #uncomment the tweepy installation in requirements.txt\n",
    "\n",
    "# Store credentials in relevant variables\n",
    "consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "\n",
    "#override tweepy.StreamListener to add logic to on_status\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "myStreamListener = MyStreamListener()\n",
    "\n",
    "# Create your Stream object with credentials\n",
    "stream = tweepy.Stream(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "# Filter your Stream variable\n",
    "stream.filter([\"clinton\", \"trump\", \"sanders\", \"cruz\"])\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = 'tweets.txt'\n",
    "\n",
    "# Initialize empty list to store tweets (this will be a list of dictionaries)\n",
    "tweets_data = []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns = ['text', 'lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Count how many tweets contain the words 'clinton', 'trump', 'sanders' and 'cruz'\n",
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 9: Here we Ingest & Stream data from APIs, with an account (with authentication credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "d\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
