{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineering Best Practices (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "* Conventions & PEP8\n",
    "    * Conventions are like social norms (or conventions). \n",
    "    * Pythonistas have their own \"conventions\" based on PEP8, which is the defacto Style Guide for Python Code.\n",
    "    * pycodestyle package: it flags violations to PEP8 style.\n",
    "    * Readability follows the Zen of Python\n",
    "\n",
    "* Modularity\n",
    "    * The idea is to break the code into smaller pieces.  We use OOP (Object Oriented Programming) to write modular code.\n",
    "    * It improves:\n",
    "        * Readability: \"Code is read much more than it is written\" (PEP8)\n",
    "        * Maintanability\n",
    "    * What modularity leverages?\n",
    "        * Packages, Classes, and Methods\n",
    "    * Class Inheritance & DRY principle \n",
    "        * Start with Parent class.\n",
    "        * Think on an specific objective and expand it (pass its functionality) to another class, the child class, which inherits methods and attributes of its Parent.\n",
    "        * Multilevel (Parent -> Child -> Grandchild) vs. Multiple (Many Parents -> Child) Inheritance\n",
    "        * This used the DRY concept, where you avoid copying & pasting code from an original class to extend it to a new extended one.\n",
    "\n",
    "* Documentation\n",
    "    * Comments, Docstrings, and Self-Documenting Code\n",
    "    * Readability follows the Zen of Python\n",
    "    * Pip & PyPi\n",
    "    * help()\n",
    "        * can be applied to many objects (to number, to a package, to a method of a package)\n",
    "        \n",
    "* Automated Testing\n",
    "    * Use tools like doctest and pytest package to automatically run and re-run your tests to ensure code is working.\n",
    "    * CI Tools: \n",
    "        * Travis CI (can help test your code when new code is added)\n",
    "        * Code Climate (can help point out if your code isn't modular)\n",
    "    \n",
    "* Version Control & Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventions & PEP8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pycodestyle's StyleGuide class to check multiple files for PEP 8 compliance.\n",
    "    # pycodestyle can be run from the command line to check a file for PEP 8 compliance. \n",
    "    # Sometimes it's useful to run this kind of check from a Python script.\n",
    "\n",
    "# Import needed package\n",
    "import pycodestyle\n",
    "\n",
    "# Create a StyleGuide instance\n",
    "style_checker = pycodestyle.StyleGuide()\n",
    "\n",
    "# Run PEP 8 check on multiple files\n",
    "result = style_checker.check_files(['/workspace/sources/datacamp/general_python_scripts/nay_pep8.py', '/workspace/sources/datacamp/general_python_scripts/yay_pep8.py'])\n",
    "\n",
    "# Print result of PEP 8 style check\n",
    "print(result.messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Packages:\n",
    "    * Recall: A package is a collection of Python modules.\n",
    "    * Adding Functionality to your package\n",
    "        * We use functions or classes  (as defined in a utils.py file) to add functionality to a package.\n",
    "    * Using  Classes to strenghten the functionality\n",
    "        * We use OOP (Object Oriented Programming) to write modular code\n",
    "    * Writing your first package:\n",
    "        * Minimial package structure: \n",
    "            * a directory called my_package (folder with the package name) and a `__init__`.py file to indicate it's a package\n",
    "        * When we import and work with our resulting package, we will be in the my_script.py file, which is in the same level as the my_package folder\n",
    "        * In the my_package folder, the utils.py file is where you define the function xyz(argument)\n",
    "        * When you are writing your code in the my_script.py, you do:\n",
    "            * import my_package.utils as mp\n",
    "            * mp.utils.xyz(argument)\n",
    "        * To make life easier for the user, we can import this class in `__init__`.py using relative import syntax:\n",
    "            * from .utils import xyz(argument)\n",
    "        * Reference for package naming: https://peps.python.org/pep-0008/#package-and-module-name\n",
    "        * Sample file structure without inheritance:  \n",
    "        <img src=\"sources/datacamp/general_python_scripts/package_structure.png\" alt=\"package structure\" width=\"400px\">\n",
    "        * Sample file structure with inheritance:  \n",
    "        <img src=\"sources/datacamp/general_python_scripts/package_structure_with_inherit.png\" alt=\"inheritance\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on int object:\n",
      "\n",
      "class int(object)\n",
      " |  int([x]) -> integer\n",
      " |  int(x, base=10) -> integer\n",
      " |  \n",
      " |  Convert a number or string to an integer, or return 0 if no arguments\n",
      " |  are given.  If x is a number, return x.__int__().  For floating point\n",
      " |  numbers, this truncates towards zero.\n",
      " |  \n",
      " |  If x is not a number or if base is given, then x must be a string,\n",
      " |  bytes, or bytearray instance representing an integer literal in the\n",
      " |  given base.  The literal can be preceded by '+' or '-' and be surrounded\n",
      " |  by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\n",
      " |  Base 0 means to interpret the base from the string as an integer literal.\n",
      " |  >>> int('0b100', base=0)\n",
      " |  4\n",
      " |  \n",
      " |  Built-in subclasses:\n",
      " |      bool\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __and__(self, value, /)\n",
      " |      Return self&value.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      True if self else False\n",
      " |  \n",
      " |  __ceil__(...)\n",
      " |      Ceiling of an Integral returns itself.\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __float__(self, /)\n",
      " |      float(self)\n",
      " |  \n",
      " |  __floor__(...)\n",
      " |      Flooring an Integral returns itself.\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Default object formatter.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getnewargs__(self, /)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __index__(self, /)\n",
      " |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      " |  \n",
      " |  __int__(self, /)\n",
      " |      int(self)\n",
      " |  \n",
      " |  __invert__(self, /)\n",
      " |      ~self\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lshift__(self, value, /)\n",
      " |      Return self<<value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __pow__(self, value, mod=None, /)\n",
      " |      Return pow(self, value, mod).\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rand__(self, value, /)\n",
      " |      Return value&self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rlshift__(self, value, /)\n",
      " |      Return value<<self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __round__(...)\n",
      " |      Rounding an Integral returns itself.\n",
      " |      \n",
      " |      Rounding with an ndigits argument also returns an integer.\n",
      " |  \n",
      " |  __rpow__(self, value, mod=None, /)\n",
      " |      Return pow(value, self, mod).\n",
      " |  \n",
      " |  __rrshift__(self, value, /)\n",
      " |      Return value>>self.\n",
      " |  \n",
      " |  __rshift__(self, value, /)\n",
      " |      Return self>>value.\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rtruediv__(self, value, /)\n",
      " |      Return value/self.\n",
      " |  \n",
      " |  __rxor__(self, value, /)\n",
      " |      Return value^self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Returns size in memory, in bytes.\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __truediv__(self, value, /)\n",
      " |      Return self/value.\n",
      " |  \n",
      " |  __trunc__(...)\n",
      " |      Truncating an Integral returns itself.\n",
      " |  \n",
      " |  __xor__(self, value, /)\n",
      " |      Return self^value.\n",
      " |  \n",
      " |  as_integer_ratio(self, /)\n",
      " |      Return integer ratio.\n",
      " |      \n",
      " |      Return a pair of integers, whose ratio is exactly equal to the original int\n",
      " |      and with a positive denominator.\n",
      " |      \n",
      " |      >>> (10).as_integer_ratio()\n",
      " |      (10, 1)\n",
      " |      >>> (-10).as_integer_ratio()\n",
      " |      (-10, 1)\n",
      " |      >>> (0).as_integer_ratio()\n",
      " |      (0, 1)\n",
      " |  \n",
      " |  bit_count(self, /)\n",
      " |      Number of ones in the binary representation of the absolute value of self.\n",
      " |      \n",
      " |      Also known as the population count.\n",
      " |      \n",
      " |      >>> bin(13)\n",
      " |      '0b1101'\n",
      " |      >>> (13).bit_count()\n",
      " |      3\n",
      " |  \n",
      " |  bit_length(self, /)\n",
      " |      Number of bits necessary to represent self in binary.\n",
      " |      \n",
      " |      >>> bin(37)\n",
      " |      '0b100101'\n",
      " |      >>> (37).bit_length()\n",
      " |      6\n",
      " |  \n",
      " |  conjugate(...)\n",
      " |      Returns self, the complex conjugate of any int.\n",
      " |  \n",
      " |  to_bytes(self, /, length=1, byteorder='big', *, signed=False)\n",
      " |      Return an array of bytes representing an integer.\n",
      " |      \n",
      " |      length\n",
      " |        Length of bytes object to use.  An OverflowError is raised if the\n",
      " |        integer is not representable with the given number of bytes.  Default\n",
      " |        is length 1.\n",
      " |      byteorder\n",
      " |        The byte order used to represent the integer.  If byteorder is 'big',\n",
      " |        the most significant byte is at the beginning of the byte array.  If\n",
      " |        byteorder is 'little', the most significant byte is at the end of the\n",
      " |        byte array.  To request the native byte order of the host system, use\n",
      " |        `sys.byteorder' as the byte order value.  Default is to use 'big'.\n",
      " |      signed\n",
      " |        Determines whether two's complement is used to represent the integer.\n",
      " |        If signed is False and a negative integer is given, an OverflowError\n",
      " |        is raised.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_bytes(bytes, byteorder='big', *, signed=False)\n",
      " |      Return the integer represented by the given array of bytes.\n",
      " |      \n",
      " |      bytes\n",
      " |        Holds the array of bytes to convert.  The argument must either\n",
      " |        support the buffer protocol or be an iterable object producing bytes.\n",
      " |        Bytes and bytearray are examples of built-in objects that support the\n",
      " |        buffer protocol.\n",
      " |      byteorder\n",
      " |        The byte order used to represent the integer.  If byteorder is 'big',\n",
      " |        the most significant byte is at the beginning of the byte array.  If\n",
      " |        byteorder is 'little', the most significant byte is at the end of the\n",
      " |        byte array.  To request the native byte order of the host system, use\n",
      " |        `sys.byteorder' as the byte order value.  Default is to use 'big'.\n",
      " |      signed\n",
      " |        Indicates whether two's complement is used to represent the integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  denominator\n",
      " |      the denominator of a rational number in lowest terms\n",
      " |  \n",
      " |  imag\n",
      " |      the imaginary part of a complex number\n",
      " |  \n",
      " |  numerator\n",
      " |      the numerator of a rational number in lowest terms\n",
      " |  \n",
      " |  real\n",
      " |      the real part of a complex number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using help() on an integer\n",
    "# It provides help on python's integer class\n",
    "help(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function most_common in module collections:\n",
      "\n",
      "most_common(self, n=None)\n",
      "    List the n most common elements and their counts from the most\n",
      "    common to the least.  If n is None, then list all element counts.\n",
      "    \n",
      "    >>> Counter('abracadabra').most_common(3)\n",
      "    [('a', 5), ('b', 2), ('r', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using help() on a method of a function\n",
    "from collections import Counter\n",
    "\n",
    "# It provides help on python's most_common() method from the Counter function in the collections package\n",
    "help(Counter.most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing your first package: my_package\n",
    "    # we create a my_package folder inside our working directory\n",
    "    # each package folder must have a __init__.py file\n",
    "# In order to make your package installable by pip you need to create a setup.py\n",
    "    # work_dir/\n",
    "    # ├── my_package\n",
    "    # │    ├── __init__.py\n",
    "    # │    └── utils.py\n",
    "    # └── setup.py\n",
    "# Keep in mind your package is located in a directory named work_dir = text_analyzer\n",
    "    # text_analyzer/\n",
    "    # ├── my_package\n",
    "    # │    ├── __init__.py\n",
    "    # │    └── utils.py\n",
    "    # └── setup.py\n",
    "\n",
    "# Import needed function from setuptools\n",
    "from setuptools import setup\n",
    "\n",
    "# Create proper setup to be used by pip\n",
    "setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='Caio',\n",
    "      packages=['text_analyzer']) #package directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing your requirements.txt\n",
    "\n",
    "# To be able to share your newly created package, you need to create two things: setup.py and requirements.txt, both under work_dir level\n",
    "    # setup.py: tells pip how to install the package (and it will be used by PyPI if you decide to publish)\n",
    "        # the packages tag: lists the location of the __init__.py files in the package.\n",
    "            # recall that we can use \"relative import\" by doing: from .utils import xyz(argument)\n",
    "        # in our case, we have just one __init.py__ in the my_package folder\n",
    "        # the utils.py is where you write the functions (or the \"functionalities\") that are part of the package\n",
    "\n",
    "    # work_dir/\n",
    "    # ├── my_package\n",
    "    # │    ├── __init__.py\n",
    "    # │    └── utils.py\n",
    "    # ├── requirements.txt\n",
    "    # └── setup.py\n",
    "\n",
    "# Given that you are running a shell session in the work_dir structure, this is the command to run the requirements.txt file\n",
    "    # pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a Class for the package\n",
    "# PEP8 Conventions:\n",
    "    # Camel case for Class names\n",
    "    # for the variable that refers to the future instance of the class: write 'self' instead of other names\n",
    "\n",
    "# Leaning points:\n",
    "    # Self and __init__: step by step idea \n",
    "        # You create a Class Person, initially with two methods: '__init__' and 'print_test'\n",
    "        # Within _init_ you define two three arguments: self, name, age.\n",
    "        # self is called: the variable that refers to a future instance of the class\n",
    "        # (name, age) are called \"instance variables\" because they store attributes that will be assigned to an instance of the class.\n",
    "        # You create an instance of this class when you assign it to a variable in your future code: person1 = Person(\"Caio\", 36).\n",
    "        # 'self' is responsible for attaching the instance variables (name, age) to the instance of the class (person1), as well as its values (\"Caio\", 36).\n",
    "        # 'self' does this by the _init_ method, defined within the Class definition.\n",
    "        # you can access and work with the instance variables (name, age) by using them within the instance methods (print_test)\n",
    "    # Accessing the Class:\n",
    "        # You add functionalities to the utils.py, in this case, we will call the file parent_class_utils.py because later we will create a child_class_utils.py \n",
    "        # You do:\n",
    "            # change (cd) to the __init__.py file's directory\n",
    "            # `from .parent_class_utils import Person`, which would correctly import this class in __init__.py using relative import syntax\n",
    "            # This will let it be easily accessible by your users.\n",
    "            # in your my_script.py you would just start with: import my_package\n",
    "    # Other methods within a Class:\n",
    "        # If a Class has only __init__ (self, etc) than this class is only a \"container\" for the attributes that will be assigned to instances.\n",
    "        # You can add pre-built methods to your Class, but you need to do the `from module_xyz import object_xyz `\n",
    "        # You can add other functionality to classes using non-public methods. By defining methods as non-public you're signifying to the user that the method is only to be used inside the package\n",
    "\n",
    "# 1) Define Class\n",
    "# 2) Once the class is written you will modify your package's __init__.py file to make it easily accessible by your users\n",
    "\n",
    "# working_dir\n",
    "# ├── my_package\n",
    "# │    ├── __init__.py\n",
    "# │    ├── utils.py \n",
    "# │    ├── parent_class_utils.py\n",
    "# ├── requirements.txt\n",
    "# └── setup.py\n",
    "# └── my_script.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the person1 object:  <__main__.Person object at 0x7fa9fc5c4bd0>\n",
      "This is the person1 name and age:  Caio , 36\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    \"\"\"A class to represent a person.\"\"\"\n",
    "\n",
    "    def __init__(self, name, age):\n",
    "        \"\"\"Initialize a Person object with a name and age.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name of the person.\n",
    "            age (int): The age of the person.\n",
    "        \"\"\"\n",
    "        self.name = name  # Assign the name attribute of the instance\n",
    "        self.age = age    # Assign the age attribute of the instance\n",
    "\n",
    "    def introduce(self):\n",
    "        \"\"\"Introduce the person.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the person's name and age.\n",
    "        \"\"\"\n",
    "        return f\"My name is {self.name} and I am {self.age} years old.\"\n",
    "\n",
    "# Instantiate the Person Class\n",
    "person1 = Person(\"Caio\", 36)\n",
    "print(\"This is the person1 object: \", person1)\n",
    "print(\"This is the person1 name and age: \", person1.name, \",\", person1.age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Structure with Class Inheritance (Parent class -> Child class)\n",
    "\n",
    "# Instead of copy-pasting the already written functionality, you will use the principles of 'DRY' and inheritance to quickly create your new Child class.\n",
    "\n",
    "# Learning Points\n",
    "    # Create another other_utils2.py to add a Child class code.\n",
    "    # `from .parent_class_utils import ParentClass`, which would correctly import this parent class in __init__.py using relative import syntax\n",
    "    # Person is the \"ParentClass\" and it will be an argument for the ChildClass defined within child_class_utils.py\n",
    "    # self now has all the methods and attributes that an instance of a ParentClass would\n",
    "    # Next, you use self as you would normally and build additional functionality unique to ChildClass\n",
    "    # Then, you instantiate the child class and can access both parent and child class functionalities\n",
    "\n",
    "# working_dir\n",
    "# ├── my_package\n",
    "# │    ├── __init__.py\n",
    "# │    ├── utils.py \n",
    "# │    ├── parent_class_utils.py\n",
    "# │    ├── child_class_utils.py\n",
    "# ├── requirements.txt\n",
    "# └── setup.py\n",
    "# └── my_script.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ParentClass object\n",
    "from .parent_class import ParentClass\n",
    "\n",
    "# Create a child class with inheritanceclass\n",
    "ChildClass(ParentClass): # The child class inherits from the parent class\n",
    "    def __init__(self):\n",
    "    # Call parent's __init__ method        \n",
    "    ParentClass.__init__(self) # Here we build an instance of ParentClass and store it into self, i.e., it initializes a ParentClass\n",
    "    # Add attribute unique to child class\n",
    "    self.child_attribute = \"I'm a child class attribute!\"\n",
    "\n",
    "# Create a ChildClass instance\n",
    "child_class = ChildClass()\n",
    "print(child_class.child_attribute)\n",
    "print(child_class.parent_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1/3\n",
    "    # Class Document - Parent Class\n",
    "    # A class for text analysis (tokenization and word count)\n",
    "\n",
    "# working_dir\n",
    "# ├── text_analyzer\n",
    "# │    ├── __init__.py\n",
    "# │    ├── counter_utils.py\n",
    "# │    ├── document.py\n",
    "# └── my_script.py\n",
    "\n",
    "# Procedures:\n",
    "    # We create a text_analyzer package that provides functions and classes to analyze text\n",
    "    # We create a document.py that hold Document class (parent) which initially works as a container for a text attribute\n",
    "    # Suppose we want to tokenize our document, i.e., you break the document into individual words (tokens) that forms a list.\n",
    "    # We put the tokenization procedure within the __init__, so that the Document instance is created and already tokenized.\n",
    "    # The tokenize method comes as _tokenize (\"_\" because this method is only used internally in the Docuemnt class).\n",
    "    # Since it is already written in the \"token_utils.py\", then we only define it and call it with the self.text attribute as argument.\n",
    "    # This will store the text as token in the _init_ method\n",
    "    # The same happens in the _count_words method, you define it and call it with the self.tokens, with the essence of Counter().\n",
    "\n",
    "# Document class (Parent Class) created within document.py\n",
    "# The Document class will perform text analysis in my_package\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        return tokenize(self.text)\n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self):\n",
    "        # Use collections.Counter to count the document's tokens\n",
    "        return Counter(self.tokens)\n",
    "\n",
    "# Import your custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet. Now, your document variable has a class \"document\" with am attribute \"text\" with a value given in datacamp_tweet\n",
    "datacamp_doc = text_analyzer.Document(datacamp_tweets)\n",
    "\n",
    "# Use dir() to show all of datacamp_doc's methods and attributes\n",
    "dir(datacamp_doc)\n",
    "\n",
    "# Run help on my_doc\n",
    "help(my_doc)\n",
    "\n",
    "# Run help on my_doc's plot method\n",
    "help(my_doc.plot_counts)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:5])\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "print(datacamp_doc.word_counts.most_common(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2/3\n",
    "    # Class SocialMedia - Child Class\n",
    "    # A child class expanding text analysis (from tokenization and word count to conting hashtags and mentions)\n",
    "\n",
    "\n",
    "# working_dir\n",
    "# ├── text_analyzer\n",
    "# │    ├── __init__.py\n",
    "# │    ├── counter_utils.py\n",
    "# │    ├── document.py\n",
    "# │    ├── tweet.py\n",
    "# └── my_script.py\n",
    "\n",
    "# Procedures:\n",
    "\n",
    "# SocialMedia class (Child Class) created within tweet.py\n",
    "# Define a SocialMedia class that is a child of the `Document class`. \n",
    "# Its extends Document tokenization and word counting to also conting hashtag and mentions.\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "        \n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='#')      \n",
    "    \n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Create a SocialMedia instance with datacamp_tweets\n",
    "dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "# Print the top five most most mentioned users\n",
    "print(dc_tweets.mention_counts.most_common(5))\n",
    "\n",
    "# Plot the most used hashtags\n",
    "text_analyzer.plot_counter(dc_tweets.mention_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3/3\n",
    "    # Class SocialMedia - Grandchild Class\n",
    "    # A child class expanding text analysis (from tokenization and word count + conting hashtags and mentions, to retweets)\n",
    "    # Here we will use Multilevel Inheritance and the super() function\n",
    "\n",
    "# Import custom text_analyzer package\n",
    "import text_analyzer\n",
    "\n",
    "# Define a Tweet class that inherits from SocialMedia\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Call parent's __init__ with super()\n",
    "        super().__init__(text)\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets()\n",
    "\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = filter_lines(self.text, first_chars='RT')\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        return SocialMedia(retweet_text)\n",
    "\n",
    "# Create instance of Tweets\n",
    "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
    "\n",
    "# Plot the most used hashtags in the retweets\n",
    "my_tweets.retweets.plot_counts('hashtag_counts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Folder structure, Packages, Functions, Classes, Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Folder structure and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) We build a folder structure for our project.\n",
    "        # The top level is the project working directory: working_dir\n",
    "        # Within the working_dir, we have 2 files:\n",
    "            # my_script.py: where you build your project code main code\n",
    "            # package_name: where you build the functionalities to be used when importing the package -> call it text_analyzer\n",
    "            # requirements.txt: where you specify the environment needed to properly use your package (python packages with versions)\n",
    "                # to install everything within this file, you do: pip install -r requirements.txt\n",
    "                # note that in this case we are only creating the environment to properly use our package (we are not installing our package)\n",
    "            # setup.py: tells pip how to install our package\n",
    "                # in our case, it contains a single call to an specific function: from setuptools import setup;\n",
    "                # Example of the setup():\n",
    "                    # setup(name='my_package', version='0.0.1', description='An example package', author='Caio', \n",
    "                    #       packages=['my_package'], \n",
    "                    #       install_requires=['matplotlib','numpy==1.15.4','pycodestyle>=2.4.0'])\n",
    "                # Now, we cd to \"working_dir\" and we can install our package with: pip install .\n",
    "        # working_dir\n",
    "        # ├── setup.py\n",
    "        # ├── requirements.txt\n",
    "        # ├── text_analyzer\n",
    "        # │    ├── __init__.py\n",
    "        # │    ├── counter_utils.py\n",
    "        # │    ├── document.py\n",
    "        # │    ├── social_media.py\n",
    "        # │    ├── tweet.py\n",
    "        # └── my_script.py\n",
    "    # 2) We create a package with minimum content\n",
    "        # PEP8 naming for the package: \"package_name\".\n",
    "        # We add a __init__.py file (let's python know that the directory is a package).\n",
    "        # Now, this package can be imported just like any other package: import text_analyzer\n",
    "        # You can also use the help to check it: help(text_analyzer)\n",
    "    # 3) We expand the packages functionalities\n",
    "        # Within text_analyzer, we added a utils.py file, i.e., a submodule (not a subpackage!) -> call it counter_utils.py\n",
    "            # counter_utils.py: we add a function \"some_function()\" to perform some analysis\n",
    "            # We can import it in my_scrip.py: import package_name.utils\n",
    "            # We can use the function: package_name.utils.some_function()\n",
    "        # We can use relative import to be easier for the user:\n",
    "            # Within the __init__.py file, we add: \n",
    "                # from .utils import some_function\n",
    "            # We can import it in my_script.py only by doing this: import package_name\n",
    "            # We can use the function without 'utils': package_name.some_function()\n",
    "        # We can add many \"utils.py\" files, just depend on how we one to organize different functionalities for this package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 4) We create functions within utils.py using a call from another package to make it easier\n",
    "    # Example: 3 functions\n",
    "\n",
    "        # First, we create a counter_utils.py function that will serve as a place for counting procedures with the Counter Class\n",
    "\n",
    "        # Recall\n",
    "            # working_dir\n",
    "            # ├── setup.py\n",
    "            # ├── requirements.txt\n",
    "            # ├── text_analyzer\n",
    "            # │    ├── __init__.py\n",
    "            # │    ├── counter_utils.py (THIS ONE)\n",
    "            # │    ├── document.py\n",
    "            # │    ├── social_media.py\n",
    "            # │    ├── tweet.py\n",
    "            # └── my_script.py\n",
    "\n",
    "        # Import needed functionality\n",
    "        from collections import Counter\n",
    "            # Counter is a Class. More specifically, a subclass of a dict.\n",
    "            # It instantiates a Counter object and ingerits dictionaries functionalitis.\n",
    "            # Thus, elements are stored as dictionary keys and their counts values. You access it as with a dict.\n",
    "\n",
    "        def plot_counter(counter, n_most_common=5):\n",
    "            # receives a counter object\n",
    "            # Subset the n_most_common items from the input counter\n",
    "            top_items = counter.most_common(n_most_common)\n",
    "                # most_common(n): a method from the Counter calss. \n",
    "                # It returns a list of the n most common elements and their counts as a tuple. It has to be applied to a counter instance.\n",
    "            # Plot `top_items`\n",
    "            plot_counter_most_common(top_items)\n",
    "\n",
    "        def sum_counters(counters):\n",
    "            # Sum the inputted counters\n",
    "            return sum(counters, Counter()) \n",
    "            # Python doesn't know how to add a list of Counters directly, so by providing an empty Counter() as the starting point,\n",
    "            # we're essentially telling Python, \"Start with an empty Counter and add each Counter in the list to it.\"\n",
    "            # While you might typically see sum() used with numbers, it can be used with other types of objects as well, as long as they support addition with each other. \n",
    "            # In this case, Counter() objects support addition with other Counter() objects, which is why it works in summing up Counter instances\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Start building the my_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) We start building my_script.py\n",
    "        # word_count is a list\n",
    "            # it's elements are a Counter:\n",
    "                # Counter({'DataCamp': 1,\n",
    "                #          'Introduction': 1,\n",
    "                #          'to': 1,\n",
    "                #          'H': 2,\n",
    "                #          'O': 2,\n",
    "                #          ...\n",
    "                #          'its': 1,\n",
    "                #          'auto': 1})\n",
    "\n",
    "        # Import local package\n",
    "        import text_analyzer\n",
    "\n",
    "        # Sum word_counts using sum_counters from text_analyzer ()\n",
    "        word_count_totals = text_analyzer.sum_counters(word_counts)\n",
    "            # it returns a Counter() object from all words in all Counter() objects within the word_counts list: word_count_totals\n",
    "            # it has one element, a Counter() object:\n",
    "                # Counter({'DataCamp': 24,\n",
    "                #          'Introduction': 27,\n",
    "                #          'to': 263,\n",
    "                #          'H': 2,\n",
    "                #           ...})\n",
    "        # Plot word_count_totals using plot_counter from text_analyzer\n",
    "        text_analyzer.plot_counter(word_count_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating Parent Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a function for separating words into a list and saving it under tokenize_utils.py\n",
    "   \n",
    "# Recall\n",
    "    # working_dir\n",
    "    # ├── setup.py\n",
    "    # ├── requirements.txt\n",
    "    # ├── text_analyzer\n",
    "    # │    ├── __init__.py\n",
    "    # │    ├── counter_utils.py\n",
    "    # │    ├── tokenize_utils.py (THIS ONE)\n",
    "    # │    ├── document.py\n",
    "    # │    ├── social_media.py\n",
    "    # │    ├── tweet.py\n",
    "    # └── my_script.py\n",
    "\n",
    "# Complete the function's docstring\n",
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"Split text into tokens using a regular expression\n",
    "\n",
    "  :param text: text to be tokenized\n",
    "  :param regex: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> tokenize('the rain in spain')\n",
    "  ['the', 'rain', 'in', 'spain']\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)\n",
    "\n",
    "# Print the docstring\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Creating Parent Classes with non-public functionalities\n",
    "\n",
    "# Recall\n",
    "        # working_dir\n",
    "        # ├── setup.py\n",
    "        # ├── requirements.txt\n",
    "        # ├── text_analyzer\n",
    "        # │    ├── __init__.py\n",
    "        # │    ├── counter_utils.py\n",
    "        # │    ├── document.py (THIS IS WHERE THE DOCUMENT CLASS IS DEFINED)\n",
    "        # │    ├── social_media.py\n",
    "        # │    ├── tweet.py\n",
    "        # └── my_script.py\n",
    "\n",
    "# Suppose we want to use a function (calling it within a Class) from another python package within a script called token_utils.py\n",
    "# We use relative import to be easier for the user, and within the __init__.py file, we add: from .token_utils import tokenize \n",
    "# With this, you can call this function directly without the need to do \"my_package.function()\" \n",
    "\n",
    "# Import function to perform tokenization \n",
    "from .tokenize_utils import tokenize\n",
    "from collections import Counter\n",
    "\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Initialize a new Document instance\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text\n",
    "        # Pre tokenize the document with non-public tokenize method\n",
    "        self.tokens = self._tokenize()\n",
    "        # Pre tokenize the document with non-public count_words\n",
    "        self.word_counts = self._count_words()\n",
    "\n",
    "    def _tokenize(self): # Use PEP8 naming with \"_function\n",
    "        return tokenize(self.text) \n",
    "\n",
    "    # Non-public method to tally document's word counts\n",
    "    def _count_words(self): # Use PEP8 naming with \"_function\n",
    "        # Use collections.Counter to count the document's tokens. Returns a Counter object\n",
    "        return Counter(self.tokens)\n",
    "    \n",
    "# Here you could already go to myscript.py and do this example:\n",
    "    # datacamp_tweets is a string\n",
    "        # Example: datacamp_tweets = '[DataCamp] Introduction to H2O AutoML --> In this tutorial, you will learn about...'\n",
    "    # Import custom text_analyzer package\n",
    "    import text_analyzer\n",
    "    # create a new document instance from datacamp_tweets\n",
    "    datacamp_doc = Document(datacamp_tweets)\n",
    "        # this will create an datacamp_doc instance with 3 attributes: \n",
    "            # text via the normal __init__ self procedure for instantiation\n",
    "            # tokens (via the _tokenize public method)\n",
    "            # word_counts (via the _count_words public method)\n",
    "\n",
    "    # print the first 5 tokens from datacamp_doc\n",
    "    print(datacamp_doc.tokens[:5])\n",
    "\n",
    "    # print the top 5 most used words in datacamp_doc. \n",
    "        # It uses the most_common method which is applied to word_counts, a Counter instance of the Counter class\n",
    "    print(datacamp_doc.word_counts.most_common(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating Child Classes (Inheritance)\n",
    "    * Instead of copy-pasting the already written Parent Class functionality and improving its code to do more specific functionalities, we will instead use the principles of 'DRY' and inheritance to create a Child Class with only these specific functionalitis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) The SocialMedia class inherits from Document and expands its functionalities\n",
    "\n",
    "# Recall\n",
    "        # working_dir\n",
    "        # ├── setup.py\n",
    "        # ├── requirements.txt\n",
    "        # ├── text_analyzer\n",
    "        # │    ├── __init__.py\n",
    "        # │    ├── counter_utils.py\n",
    "        # │    ├── document.py \n",
    "        # │    ├── social_media.py (THIS IS WHERE THE SOCIAL MEDIA CLASS IS DEFINED)\n",
    "        # │    ├── tweet.py\n",
    "        # └── my_script.py\n",
    "\n",
    "# We had a Document Class that is used to analyze text:\n",
    "    # It serves as a container for a text (self.text)\n",
    "    # It tokanizes the text, transforming into a list (self.tokens)\n",
    "    # It counts the words of the list using the Counter class methods (self.word_counts)\n",
    "\n",
    "# Now, we want to expand particularize this class to work with Social Media text. \n",
    "# We build a Child Class SocialMedia that inherits from its Parent Class (Document)\n",
    "# We add functionalities to perfome social media text procedures\n",
    "\n",
    "# Import Parent Class (document.py) object for use in defining the Child Class\n",
    "from .document import Document\n",
    "\n",
    "# Create a Child Class inheriting from its Parent Class\n",
    "class SocialMedia(Document):\n",
    "    \n",
    "    # Initialize a new SocialMedia instance, inheriting Document Class functionalities\n",
    "    def __init__(self, text): \n",
    "        # Here, we call the Parent Class __init__ method, which builds an instance of Parent and stores back into the SocialMedia self.\n",
    "        # This means that self now also have all functionalities from Document \n",
    "        Document.__init__(self) \n",
    "        # Now, we use self normally to build the other attributes particular to the SocialMedia Class\n",
    "            # Note that both attributes below will be an instance of a Counter Class because it uses the word_counts method, \n",
    "            # which uses collections.Counter to count the document's tokens and returns a Counter object\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()\n",
    "        \n",
    "    def _count_hashtags(self):\n",
    "        # Filter attribute so only words starting with '#' remain\n",
    "            # It uses the word_counts attribute from the Document class, which is a Counter instance of the Counter class, i.e., words and its counts in a dict.\n",
    "            # It also uses filter_word_counts(), a particular function created to filter words by their first characters.\n",
    "        return filter_word_counts(self.word_counts, first_char='#')      \n",
    "    \n",
    "    def _count_mentions(self):\n",
    "        # Filter attribute so only words starting with '@' remain\n",
    "            # It uses the word_counts attribute from the Document class, which is a Counter instance of the Counter class, i.e., words and its counts in a dict.\n",
    "            # It also uses filter_word_counts(), a particular function created to filter words by their first characters.\n",
    "        return filter_word_counts(self.word_counts, first_char='@')\n",
    "    \n",
    "# Here you could already go to myscript.py and do this example:\n",
    "    # datacamp_tweets is a string\n",
    "        # Example: datacamp_tweets = '[DataCamp] Introduction to H2O AutoML --> In this tutorial, you will learn about...'\n",
    "    # Import custom text_analyzer package\n",
    "    import text_analyzer\n",
    "\n",
    "    # Create a SocialMedia instance with datacamp_tweets\n",
    "    dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "    # Print the top five most most mentioned users\n",
    "    print(dc_tweets.mention_counts.most_common(5))\n",
    "\n",
    "    # Plot the most used hashtags\n",
    "    text_analyzer.plot_counter(dc_tweets.mention_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating GrandChild Classes (Multilevel Inheritance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) The Tweets class inherits from SocialMedia and expands its functionalities\n",
    "\n",
    "# Recall\n",
    "        # working_dir\n",
    "        # ├── setup.py\n",
    "        # ├── requirements.txt\n",
    "        # ├── text_analyzer\n",
    "        # │    ├── __init__.py\n",
    "        # │    ├── counter_utils.py\n",
    "        # │    ├── document.py \n",
    "        # │    ├── social_media.py \n",
    "        # │    ├── tweet.py (THIS IS WHERE THE TWEET CLASS IS DEFINED)\n",
    "        # └── my_script.py\n",
    "\n",
    "# Here we change the essence of the inheritance procedure\n",
    "# We will use the super() function with the __init__ to instantiate a Parent or Child class within the respective Child or GrandChild Class\n",
    "\n",
    "class Tweets(SocialMedia):\n",
    "    def __init__(self, text):\n",
    "        # Here, we call parent's __init__ with super(), which builds an instance of Document and stores back into the SocialMedia self.\n",
    "        # However, since we only provide 'text', it only inherits the text functionality from Document\n",
    "        super().__init__(text)\n",
    "        # Define retweets attribute with non-public method\n",
    "        self.retweets = self._process_retweets()\n",
    "\n",
    "    def _process_retweets(self):\n",
    "        # Filter tweet text to only include retweets\n",
    "        retweet_text = filter_lines(self.text, first_chars='RT')\n",
    "        # Return retweet_text as a SocialMedia object\n",
    "        return SocialMedia(retweet_text)\n",
    "\n",
    "# Here you could already go to myscript.py and do this example:\n",
    "    # datacamp_tweets is a string\n",
    "        # Example: datacamp_tweets = '[DataCamp] Introduction to H2O AutoML --> In this tutorial, you will learn about...'\n",
    "    # Import custom text_analyzer package\n",
    "    import text_analyzer\n",
    "\n",
    "    # Create instance of Tweets\n",
    "    my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
    "\n",
    "    # Plot the most used hashtags in the tweets\n",
    "    my_tweets.plot_counts('hashtag_counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comments\n",
    "    * Are used inline\n",
    "    * Cannot be seen by end users unless they enter the code\n",
    "    * Focus on \"Why the code is doing what it is doing\" (and not \"What the code is doing\")\n",
    "\n",
    "* Docstrings\n",
    "    * Documentation for end users\n",
    "    * It is output when a user calls help() on functions and classes\n",
    "\n",
    "* Redability\n",
    "    * Self-documenting code (\"def is_even\" is better than \"def check_even\")\n",
    "    * If the code doesn't fit the screen, maybe it needs to be refactored (broken down into modules)\n",
    "\n",
    "* For tests\n",
    "    * Sphinx (generates HTML for the documentation)\n",
    "    * Code Climate (can help point out if your code isn't modular)\n",
    "    * Travis CI (can help test your code when new code is added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function square in module __main__:\n",
      "\n",
      "square(x)\n",
      "    Square the number x    \n",
      "    \n",
      "    :param x: number to square    \n",
      "    :return: x squared    \n",
      "    \n",
      "    >>> square(2)\n",
      "    4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Suppose we build a square function:\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Square the number x    \n",
    "\n",
    "    :param x: number to square    \n",
    "    :return: x squared    \n",
    "\n",
    "    >>> square(2)\n",
    "    4    \n",
    "    \"\"\"\n",
    "    # `x * x` is faster than `x ** 2`\n",
    "    # reference: https://stackoverflow.com/a/29055266/5731525return x * x\n",
    "\n",
    "# Calling the help() on this function\n",
    "help(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of docstring documentation for the SocialMedia Class\n",
    "from text_analyzer import Document\n",
    "\n",
    "class SocialMedia(Document):\n",
    "    \"\"\"Analyze text data from social media\n",
    "    \n",
    "    :param text: social media text to analyze\n",
    "\n",
    "    :ivar hashtag_counts: Counter object containing counts of hashtags used in text\n",
    "    :ivar mention_counts: Counter object containing counts of @mentions used in text\n",
    "    \"\"\"\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text)\n",
    "        self.hashtag_counts = self._count_hashtags()\n",
    "        self.mention_counts = self._count_mentions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing\n",
    "    * A test folder will be included in the folder structure\n",
    "    * Easy python options for testing\n",
    "        * doctest\n",
    "        * pytest\n",
    "    * Documentation for tests\n",
    "        * Sphinx (generates HTML for the documentation)\n",
    "        * CI Testing tools:\n",
    "            * Travis CI (Continuous Integration)\n",
    "                * When you add new test to your code (because, normally, we all do it continuously), than Travis will automatically test for you.\n",
    "            * Schedule tools\n",
    "                * By scheduling a build, your tests can be run periodically even without adding new code (maybe a dependency was changed and you didn't know, so a error would be raised even when the main code was not updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 9, in __main__.square\n",
      "Failed example:\n",
      "    square(2)\n",
      "Expected:\n",
      "    4    \n",
      "Got nothing\n",
      "**********************************************************************\n",
      "File \"__main__\", line 24, in __main__.tokenize\n",
      "Failed example:\n",
      "    tokenize('the rain in spain')\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.11/doctest.py\", line 1355, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.tokenize[0]>\", line 1, in <module>\n",
      "        tokenize('the rain in spain')\n",
      "      File \"/tmp/ipykernel_441/2143170907.py\", line 27, in tokenize\n",
      "        return re.findall(regex, text, flags=re.IGNORECASE)\n",
      "               ^^\n",
      "    NameError: name 're' is not defined\n",
      "**********************************************************************\n",
      "2 items had failures:\n",
      "   1 of   1 in __main__.square\n",
      "   1 of   1 in __main__.tokenize\n",
      "***Test Failed*** 2 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=2, attempted=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doctest\n",
    "import doctest\n",
    "\n",
    "# Run the testmod function from doctest to test your function's example code\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytest\n",
    "    # Pytest looks for files that start or end with \"test\"\n",
    "\n",
    "# Recall\n",
    "        # working_dir\n",
    "        # ├── setup.py\n",
    "        # ├── requirements.txt\n",
    "        # ├── text_analyzer\n",
    "        # │    ├── __init__.py\n",
    "        # │    ├── counter_utils.py\n",
    "        # │    ├── document.py \n",
    "        # │    ├── social_media.py \n",
    "        # │    └── tweet.py (THIS IS WHERE THE TWEET CLASS IS DEFINED)\n",
    "        # ├── tests\n",
    "        # │    └── test_document.py\n",
    "        # └── my_script.py\n",
    "\n",
    "# This will be written in the test_document.py\n",
    "from text_analyzer import Document\n",
    "\n",
    "# Example 1: Testing the Document class token attribute\n",
    "def test_document_tokens():    \n",
    "    doc = Document('a e i o u')\n",
    "    \n",
    "    assert doc.tokens == ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "# Example 2: Testing edge case of a blank document\n",
    "def test_document_empty():    \n",
    "    doc = Document('')\n",
    "    \n",
    "    assert doc.tokens == []\n",
    "    assert doc.word_counts == Counter()\n",
    "\n",
    "# Example 3: Comparing instances of the same Class\n",
    "# Create 2 identical Document objects\n",
    "doc_a = Document('a e i o u')\n",
    "doc_b = Document('a e i o u')\n",
    "# Check if objects are ==\n",
    "print(doc_a == doc_b) # -> FALSE\n",
    "\n",
    "# Check if attributes are ==\n",
    "print(doc_a.tokens == doc_b.tokens)  # -> TRUE\n",
    "print(doc_a.word_counts == doc_b.word_counts)  # -> TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Pytest\n",
    "\n",
    "from collections import Counter\n",
    "from text_analyzer import SocialMedia\n",
    "\n",
    "# Create an instance of SocialMedia for testing\n",
    "test_post = 'learning #python & #rstats is awesome! thanks @datacamp!'\n",
    "sm_post = SocialMedia(test_post)\n",
    "\n",
    "# Test hashtag counts are created properly\n",
    "def test_social_media_hashtags():\n",
    "    expected_hashtag_counts = Counter({'#python': 1, '#rstats': 1})\n",
    "    assert sm_post.hashtag_counts == expected_hashtag_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
